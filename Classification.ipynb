{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32a0cfa76107108",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Words Classification\n",
    "\n",
    "In this document the classification of words is performed using the embeddings, both in CLASS layer and in the second hierarchical level whether it is a SECTION or DIVISION."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by importing all the necessary libraries, that will be used."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5445eb00daa5656"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce381dea3d17d214",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:33:14.740938900Z",
     "start_time": "2024-02-24T16:33:01.788696500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nomic import embed\n",
    "import chromadb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l1_l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then load the word with the hierarchy from the csv file and create a dataframe to store the words and remove the # and the numbers from the words."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71c185163472e3c7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32202772b91e3940",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:30.113702Z",
     "start_time": "2024-02-24T13:12:30.074002200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                             word\n0     CLASS I WORDS EXPRESSING ABSTRACT RELATIONS\n1                            SECTION I. EXISTENCE\n2                                       Existence\n3                                     Inexistence\n4                                  Substantiality\n...                                           ...\n1102                                       Clergy\n1103                                        Laity\n1104                                         Rite\n1105                                   Canonicals\n1106                                       Temple\n\n[1106 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CLASS I WORDS EXPRESSING ABSTRACT RELATIONS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SECTION I. EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Existence</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Inexistence</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Substantiality</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>Clergy</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>Laity</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>Rite</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>Canonicals</td>\n    </tr>\n    <tr>\n      <th>1106</th>\n      <td>Temple</td>\n    </tr>\n  </tbody>\n</table>\n<p>1106 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the word with the hierarchy from the csv file\n",
    "complete = pd.read_csv('bold_words_with_numbers3.txt', header=None, names=['word'])\n",
    "\n",
    "# Create a dataframe to store the words\n",
    "df = complete.copy()\n",
    "\n",
    "# Remove the # and the numbers from the words\n",
    "df['word'] = df['word'].str.replace(r'#\\d+[a-z]?\\.\\s*', '', regex=True)\n",
    "\n",
    "#keep only the words that are not empty\n",
    "df = df[df['word'].str.len() > 0]\n",
    "\n",
    "#remove any remaining cases\n",
    "df['word'] = df['word'].str.replace(r'#\\d+[a-z]\\s+', '', regex=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After that the initialisation of the class number and the sec/div number columns is performed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fff469fb981c55a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260406450205c520",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:31.131835Z",
     "start_time": "2024-02-24T13:12:31.107717100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                             word  class  sec_div\n0     CLASS I WORDS EXPRESSING ABSTRACT RELATIONS      0        0\n1                            SECTION I. EXISTENCE      0        0\n2                                       Existence      0        0\n3                                     Inexistence      0        0\n4                                  Substantiality      0        0\n...                                           ...    ...      ...\n1102                                       Clergy      0        0\n1103                                        Laity      0        0\n1104                                         Rite      0        0\n1105                                   Canonicals      0        0\n1106                                       Temple      0        0\n\n[1106 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>class</th>\n      <th>sec_div</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CLASS I WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SECTION I. EXISTENCE</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Existence</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Inexistence</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Substantiality</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>Clergy</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>Laity</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>Rite</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>Canonicals</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1106</th>\n      <td>Temple</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1106 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialise the Class number and the Sec/Div number columns\n",
    "# Create the class number\n",
    "df['class'] = 0\n",
    "\n",
    "# Create the section/division number\n",
    "df['sec_div'] = 0\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below function `process_hierarchy` processes a DataFrame by iterating through each row to manage counters related to classes and sections or divisions within a document. Initially, it looks for 'CLASS' in the 'word' column to start the new counts. When a 'CLASS' is found the class counter is incremented and it resets the section/division counter and starts looking for 'SECTION' or 'DIVISION'. If 'SECTION' or 'DIVISION' is found, it increments the counter. Finding a 'DIVISION' changes the focus solely to 'DIVISION' until the next 'CLASS' is encountered. Finally, it assigns these counters to the new columns 'class' and 'sec_div' and removes any rows containing 'CLASS', 'SECTION', or 'DIVISION' keywords, returning the cleaned DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80aa364e7244a6b4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874ed2ae3a6b827f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:34.095918300Z",
     "start_time": "2024-02-24T13:12:34.083411200Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_hierarchy(df):\n",
    "    class_counter = 0\n",
    "    sec_div_counter = 0\n",
    "    looking_for = 'CLASS'  # Start by looking for 'CLASS'\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        word = row['word']\n",
    "        \n",
    "        # Check for 'CLASS' and increment class counter\n",
    "        if 'CLASS' in word:\n",
    "            class_counter += 1\n",
    "            sec_div_counter = 0  # Reset section/division counter\n",
    "            looking_for = 'SECTION'  # Start looking for 'SECTION' by default\n",
    "        \n",
    "        # Check for 'SECTION' or 'DIVISION' and increment section/division counter\n",
    "        elif looking_for == 'SECTION' and 'SECTION' in word or 'DIVISION' in word:\n",
    "            sec_div_counter += 1\n",
    "            # If 'DIVISION' is found, only look for 'DIVISION' until the next 'CLASS'\n",
    "            if 'DIVISION' in word:\n",
    "                looking_for = 'DIVISION'\n",
    "        \n",
    "        # Assign class counter and section/division counter to the current row\n",
    "        df.at[index, 'class'] = class_counter\n",
    "        df.at[index, 'sec_div'] = sec_div_counter\n",
    "        \n",
    "    df = df[~df['word'].str.contains('CLASS|SECTION|DIVISION')]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4165990ae390b746",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:35.681236200Z",
     "start_time": "2024-02-24T13:12:35.593839200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  word  class  sec_div\n2            Existence      1        1\n3          Inexistence      1        1\n4       Substantiality      1        1\n5     Unsubstantiality      1        1\n6       Intrinsicality      1        1\n...                ...    ...      ...\n1102            Clergy      6        5\n1103             Laity      6        5\n1104              Rite      6        5\n1105        Canonicals      6        5\n1106            Temple      6        5\n\n[1057 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>class</th>\n      <th>sec_div</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Existence</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Inexistence</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Substantiality</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Unsubstantiality</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Intrinsicality</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>Clergy</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>Laity</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>Rite</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>Canonicals</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1106</th>\n      <td>Temple</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the function to process the hierarchy\n",
    "df = process_hierarchy(df)\n",
    "\n",
    "#preview the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then the embeddings are retrieved using the `embed.text` method from the nomic library. The `model` parameter is set to `nomic-embed-text-v1` and the `task_type` parameter is set to `classification` for the generation of embeddings catered to classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1658120ca2ec476"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93789ae0fd170cf6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:11:37.380663300Z",
     "start_time": "2024-02-24T13:11:31.120250600Z"
    }
   },
   "outputs": [],
   "source": [
    "#retrieve the embeddings from the nomic library\n",
    "output = embed.text(\n",
    "    texts=df['word'].tolist(),\n",
    "    model='nomic-embed-text-v1',\n",
    "    task_type='classification',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The chromadb client is initialised to interact with the vector database and a collection called `nomic_classification` is created. The documents, embeddings, metadatas, and ids are added to the collection."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a20200d49e000b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1daef6b1c95c23b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:43.515053400Z",
     "start_time": "2024-02-24T13:12:43.391463700Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a client to interact with the vector database\n",
    "chroma_client = chromadb.PersistentClient(\"./chromadb\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#create a collection called nomic_clustering\n",
    "collection = chroma_client.create_collection(name=\"nomic_classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T17:16:05.526540600Z",
     "start_time": "2024-02-24T17:16:05.500540Z"
    }
   },
   "id": "7a070e6c1da4208f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e7151e703dd81f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T17:16:15.507982500Z",
     "start_time": "2024-02-24T17:16:15.479981900Z"
    }
   },
   "outputs": [],
   "source": [
    "#add the documents, embeddings, metadatas, and ids to the collection\n",
    "collection.add(\n",
    "    documents=df['word'].tolist(),\n",
    "    embeddings=output['embeddings'],\n",
    "    metadatas=[{\"word\": word} for word in df['word'].tolist()],\n",
    "    ids=[f\"word{i}\" for i in range(len(df['word'].tolist()))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e075fc40e32ff16b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:48.019077400Z",
     "start_time": "2024-02-24T13:12:48.007231400Z"
    }
   },
   "outputs": [],
   "source": [
    "#get the collection\n",
    "collection = chroma_client.get_collection(name=\"nomic_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#delete the collection if needed\n",
    "#chroma_client.delete_collection(name=\"nomic_clustering\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T17:16:25.846170200Z",
     "start_time": "2024-02-24T17:16:25.816168600Z"
    }
   },
   "id": "994a2039077813ba",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "The embeddings and the words are retrieved from the collection and the classification is created with the embeddings. The duplicates are dropped and the classification is merged with the original dataframe to add the class and sec_div columns."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c94370f366b25a3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301b60eddc1da4c0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:51.914006200Z",
     "start_time": "2024-02-24T13:12:51.759094200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6  \\\n0    -0.029755 -0.026367 -0.012779 -0.047302  0.025482  0.067017  0.004402   \n1    -0.010292  0.019257 -0.017593 -0.038849  0.025085  0.058319  0.003544   \n2     0.038696 -0.010262 -0.013084 -0.060669 -0.034119  0.018646  0.014557   \n3     0.007351 -0.001904 -0.016907 -0.080200 -0.023941  0.006577  0.042511   \n4     0.033813  0.013992 -0.030975 -0.040100 -0.025711  0.073120  0.034760   \n...        ...       ...       ...       ...       ...       ...       ...   \n1052  0.003222  0.012016 -0.026779 -0.062622 -0.029129 -0.013229 -0.036713   \n1053 -0.017761  0.020966 -0.022141 -0.068909 -0.021332  0.077820  0.061707   \n1054  0.010719  0.049469 -0.036987 -0.062286  0.003099  0.019135  0.003527   \n1055  0.020142  0.006626 -0.035675 -0.046814 -0.005482  0.024155  0.011139   \n1056  0.003523 -0.028534 -0.035370 -0.047882  0.015419 -0.011162  0.028427   \n\n             7         8         9  ...       761       762       763  \\\n0     0.016739 -0.065491  0.003429  ... -0.004848  0.023834  0.031921   \n1     0.032318 -0.047516 -0.004955  ...  0.003414 -0.006088  0.015236   \n2     0.017441 -0.054077 -0.009644  ...  0.021851 -0.002119  0.053833   \n3     0.013557 -0.055969  0.013985  ...  0.022186  0.027924 -0.003046   \n4    -0.000263 -0.023941 -0.001348  ... -0.008667  0.004883  0.051147   \n...        ...       ...       ...  ...       ...       ...       ...   \n1052  0.031189 -0.044830 -0.008881  ... -0.004864 -0.006489  0.029816   \n1053  0.007278 -0.046021 -0.044373  ...  0.009666 -0.001984  0.058655   \n1054 -0.003384 -0.029724  0.024185  ... -0.005856  0.006557  0.037598   \n1055 -0.030060  0.010170 -0.009857  ... -0.014580  0.026886  0.042694   \n1056 -0.001828 -0.008820  0.002476  ...  0.006496  0.024887  0.026566   \n\n           764       765       766       767               word  class  \\\n0     0.008949  0.039398 -0.033813  0.005913          Existence      1   \n1    -0.028397  0.063965 -0.087158 -0.001468        Inexistence      1   \n2     0.003244  0.031021 -0.066040 -0.023254      Consanguinity      1   \n3     0.032745  0.010971 -0.052429 -0.011940         Trisection      1   \n4    -0.006226 -0.013985 -0.035614 -0.030762          Innocence      6   \n...        ...       ...       ...       ...                ...    ...   \n1052  0.028076  0.011002 -0.025818 -0.019547              Knave      6   \n1053  0.011986  0.012474 -0.026489 -0.018188  Disinterestedness      6   \n1054  0.008789  0.003222 -0.040863 -0.024185        Selfishness      6   \n1055  0.005581 -0.009171 -0.081665 -0.013771             Virtue      6   \n1056 -0.003654 -0.018295 -0.044769 -0.010315               Vice      6   \n\n      sec_div  \n0           1  \n1           1  \n2           2  \n3           5  \n4           4  \n...       ...  \n1052        4  \n1053        4  \n1054        4  \n1055        4  \n1056        4  \n\n[1057 rows x 771 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>word</th>\n      <th>class</th>\n      <th>sec_div</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.029755</td>\n      <td>-0.026367</td>\n      <td>-0.012779</td>\n      <td>-0.047302</td>\n      <td>0.025482</td>\n      <td>0.067017</td>\n      <td>0.004402</td>\n      <td>0.016739</td>\n      <td>-0.065491</td>\n      <td>0.003429</td>\n      <td>...</td>\n      <td>-0.004848</td>\n      <td>0.023834</td>\n      <td>0.031921</td>\n      <td>0.008949</td>\n      <td>0.039398</td>\n      <td>-0.033813</td>\n      <td>0.005913</td>\n      <td>Existence</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.010292</td>\n      <td>0.019257</td>\n      <td>-0.017593</td>\n      <td>-0.038849</td>\n      <td>0.025085</td>\n      <td>0.058319</td>\n      <td>0.003544</td>\n      <td>0.032318</td>\n      <td>-0.047516</td>\n      <td>-0.004955</td>\n      <td>...</td>\n      <td>0.003414</td>\n      <td>-0.006088</td>\n      <td>0.015236</td>\n      <td>-0.028397</td>\n      <td>0.063965</td>\n      <td>-0.087158</td>\n      <td>-0.001468</td>\n      <td>Inexistence</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.038696</td>\n      <td>-0.010262</td>\n      <td>-0.013084</td>\n      <td>-0.060669</td>\n      <td>-0.034119</td>\n      <td>0.018646</td>\n      <td>0.014557</td>\n      <td>0.017441</td>\n      <td>-0.054077</td>\n      <td>-0.009644</td>\n      <td>...</td>\n      <td>0.021851</td>\n      <td>-0.002119</td>\n      <td>0.053833</td>\n      <td>0.003244</td>\n      <td>0.031021</td>\n      <td>-0.066040</td>\n      <td>-0.023254</td>\n      <td>Consanguinity</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.007351</td>\n      <td>-0.001904</td>\n      <td>-0.016907</td>\n      <td>-0.080200</td>\n      <td>-0.023941</td>\n      <td>0.006577</td>\n      <td>0.042511</td>\n      <td>0.013557</td>\n      <td>-0.055969</td>\n      <td>0.013985</td>\n      <td>...</td>\n      <td>0.022186</td>\n      <td>0.027924</td>\n      <td>-0.003046</td>\n      <td>0.032745</td>\n      <td>0.010971</td>\n      <td>-0.052429</td>\n      <td>-0.011940</td>\n      <td>Trisection</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.033813</td>\n      <td>0.013992</td>\n      <td>-0.030975</td>\n      <td>-0.040100</td>\n      <td>-0.025711</td>\n      <td>0.073120</td>\n      <td>0.034760</td>\n      <td>-0.000263</td>\n      <td>-0.023941</td>\n      <td>-0.001348</td>\n      <td>...</td>\n      <td>-0.008667</td>\n      <td>0.004883</td>\n      <td>0.051147</td>\n      <td>-0.006226</td>\n      <td>-0.013985</td>\n      <td>-0.035614</td>\n      <td>-0.030762</td>\n      <td>Innocence</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>0.003222</td>\n      <td>0.012016</td>\n      <td>-0.026779</td>\n      <td>-0.062622</td>\n      <td>-0.029129</td>\n      <td>-0.013229</td>\n      <td>-0.036713</td>\n      <td>0.031189</td>\n      <td>-0.044830</td>\n      <td>-0.008881</td>\n      <td>...</td>\n      <td>-0.004864</td>\n      <td>-0.006489</td>\n      <td>0.029816</td>\n      <td>0.028076</td>\n      <td>0.011002</td>\n      <td>-0.025818</td>\n      <td>-0.019547</td>\n      <td>Knave</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>-0.017761</td>\n      <td>0.020966</td>\n      <td>-0.022141</td>\n      <td>-0.068909</td>\n      <td>-0.021332</td>\n      <td>0.077820</td>\n      <td>0.061707</td>\n      <td>0.007278</td>\n      <td>-0.046021</td>\n      <td>-0.044373</td>\n      <td>...</td>\n      <td>0.009666</td>\n      <td>-0.001984</td>\n      <td>0.058655</td>\n      <td>0.011986</td>\n      <td>0.012474</td>\n      <td>-0.026489</td>\n      <td>-0.018188</td>\n      <td>Disinterestedness</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>0.010719</td>\n      <td>0.049469</td>\n      <td>-0.036987</td>\n      <td>-0.062286</td>\n      <td>0.003099</td>\n      <td>0.019135</td>\n      <td>0.003527</td>\n      <td>-0.003384</td>\n      <td>-0.029724</td>\n      <td>0.024185</td>\n      <td>...</td>\n      <td>-0.005856</td>\n      <td>0.006557</td>\n      <td>0.037598</td>\n      <td>0.008789</td>\n      <td>0.003222</td>\n      <td>-0.040863</td>\n      <td>-0.024185</td>\n      <td>Selfishness</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>0.020142</td>\n      <td>0.006626</td>\n      <td>-0.035675</td>\n      <td>-0.046814</td>\n      <td>-0.005482</td>\n      <td>0.024155</td>\n      <td>0.011139</td>\n      <td>-0.030060</td>\n      <td>0.010170</td>\n      <td>-0.009857</td>\n      <td>...</td>\n      <td>-0.014580</td>\n      <td>0.026886</td>\n      <td>0.042694</td>\n      <td>0.005581</td>\n      <td>-0.009171</td>\n      <td>-0.081665</td>\n      <td>-0.013771</td>\n      <td>Virtue</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>0.003523</td>\n      <td>-0.028534</td>\n      <td>-0.035370</td>\n      <td>-0.047882</td>\n      <td>0.015419</td>\n      <td>-0.011162</td>\n      <td>0.028427</td>\n      <td>-0.001828</td>\n      <td>-0.008820</td>\n      <td>0.002476</td>\n      <td>...</td>\n      <td>0.006496</td>\n      <td>0.024887</td>\n      <td>0.026566</td>\n      <td>-0.003654</td>\n      <td>-0.018295</td>\n      <td>-0.044769</td>\n      <td>-0.010315</td>\n      <td>Vice</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows × 771 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the embeddings and the words from the collection\n",
    "embeddings = collection.get(include=[\"embeddings\", \"documents\"])['embeddings']\n",
    "words = collection.get(include=[\"embeddings\", \"documents\"])['documents']\n",
    "\n",
    "classification = pd.DataFrame(embeddings)\n",
    "\n",
    "classification['word'] = words\n",
    "\n",
    "#drop duplicates\n",
    "classification = classification.drop_duplicates(subset='word')\n",
    "\n",
    "#merge the classification with the original dataframe to add the class and sec_div columns\n",
    "classification = classification.merge(df, on='word')\n",
    "\n",
    "#show the classification\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification on the CLASS layer\n",
    "\n",
    "After the classification dataframe is created, we are able to begin the classification process on CLASS level."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b571807b9210383"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data is prepared for the classification by dropping the word, class, and sec_div columns and the X and y are created then data is split into training and testing sets. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74a9771c7f43ff21"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970ce4a9f7f7bc65",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:57.384417100Z",
     "start_time": "2024-02-24T13:12:57.368605700Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare the data for the classification\n",
    "X = classification.drop(['word', 'class', 'sec_div'], axis=1)\n",
    "\n",
    "y = classification['class']-1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After that the logistic regression is performed to classify the words and the classification report is printed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0133ffc7702535"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d70f79e248f594",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:12:58.188302200Z",
     "start_time": "2024-02-24T13:12:58.130976200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66        41\n",
      "           1       0.75      0.50      0.60        30\n",
      "           2       0.57      0.52      0.54        25\n",
      "           3       0.58      0.54      0.56        28\n",
      "           4       0.61      0.69      0.65        49\n",
      "           5       0.67      0.79      0.73        39\n",
      "\n",
      "    accuracy                           0.64       212\n",
      "   macro avg       0.64      0.62      0.62       212\n",
      "weighted avg       0.64      0.64      0.63       212\n"
     ]
    }
   ],
   "source": [
    "# perform logistic regression to classify the words\n",
    "logisticRegr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy is 0.64, which is not very high. We can use optuna to optimize the hyperparameters of the logistic regression."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81ae81200c47e28c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "414156d59e88a8a1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:21:34.336023600Z",
     "start_time": "2024-02-24T13:21:29.857737300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:21:29,857] A new study created in memory with name: no-name-f70d9131-f002-40b5-b915-cd25875543a6\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:29,939] Trial 0 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 0.025811986200456105}. Best is trial 0 with value: 0.6037735849056604.\n",
      "[I 2024-02-24 15:21:30,076] Trial 1 finished with value: 0.6462264150943396 and parameters: {'penalty': 'l2', 'C': 544.7446567924222}. Best is trial 1 with value: 0.6462264150943396.\n",
      "[I 2024-02-24 15:21:30,102] Trial 2 finished with value: 0.25 and parameters: {'penalty': 'l2', 'C': 0.04078442486190641}. Best is trial 1 with value: 0.6462264150943396.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:30,180] Trial 3 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 0.09456333437954717}. Best is trial 1 with value: 0.6462264150943396.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:30,255] Trial 4 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 0.00014646221153326517}. Best is trial 1 with value: 0.6462264150943396.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:30,331] Trial 5 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 21208.939162394985}. Best is trial 1 with value: 0.6462264150943396.\n",
      "[I 2024-02-24 15:21:30,366] Trial 6 finished with value: 0.23113207547169812 and parameters: {'penalty': 'l2', 'C': 1.33428758034716e-05}. Best is trial 1 with value: 0.6462264150943396.\n",
      "[I 2024-02-24 15:21:30,388] Trial 7 finished with value: 0.23113207547169812 and parameters: {'penalty': 'l2', 'C': 0.0017301583048767973}. Best is trial 1 with value: 0.6462264150943396.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:30,463] Trial 8 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 2.026607028818805}. Best is trial 1 with value: 0.6462264150943396.\n",
      "[I 2024-02-24 15:21:30,568] Trial 9 finished with value: 0.5943396226415094 and parameters: {'penalty': 'l2', 'C': 52671.34221150557}. Best is trial 1 with value: 0.6462264150943396.\n",
      "[I 2024-02-24 15:21:30,713] Trial 10 finished with value: 0.6509433962264151 and parameters: {'penalty': 'l2', 'C': 132.81359398828846}. Best is trial 10 with value: 0.6509433962264151.\n",
      "[I 2024-02-24 15:21:30,871] Trial 11 finished with value: 0.6462264150943396 and parameters: {'penalty': 'l2', 'C': 192.95436336777732}. Best is trial 10 with value: 0.6509433962264151.\n",
      "[I 2024-02-24 15:21:31,017] Trial 12 finished with value: 0.6556603773584906 and parameters: {'penalty': 'l2', 'C': 98.9141823389882}. Best is trial 12 with value: 0.6556603773584906.\n",
      "[I 2024-02-24 15:21:31,146] Trial 13 finished with value: 0.6745283018867925 and parameters: {'penalty': 'l2', 'C': 17.628723660275377}. Best is trial 13 with value: 0.6745283018867925.\n",
      "[I 2024-02-24 15:21:31,253] Trial 14 finished with value: 0.6745283018867925 and parameters: {'penalty': 'l2', 'C': 11.116846125294954}. Best is trial 13 with value: 0.6745283018867925.\n",
      "[I 2024-02-24 15:21:31,333] Trial 15 finished with value: 0.6839622641509434 and parameters: {'penalty': 'l2', 'C': 3.0180237482398953}. Best is trial 15 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:21:31,422] Trial 16 finished with value: 0.6886792452830188 and parameters: {'penalty': 'l2', 'C': 5.449257421576762}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,468] Trial 17 finished with value: 0.6320754716981132 and parameters: {'penalty': 'l2', 'C': 0.5137174910478495}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,589] Trial 18 finished with value: 0.6367924528301887 and parameters: {'penalty': 'l2', 'C': 3158.228635488226}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,641] Trial 19 finished with value: 0.6367924528301887 and parameters: {'penalty': 'l2', 'C': 1.2129854363505366}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,732] Trial 20 finished with value: 0.6745283018867925 and parameters: {'penalty': 'l2', 'C': 8.170565190878284}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,852] Trial 21 finished with value: 0.6745283018867925 and parameters: {'penalty': 'l2', 'C': 20.387424465370355}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,884] Trial 22 finished with value: 0.5990566037735849 and parameters: {'penalty': 'l2', 'C': 0.21146411849978097}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:31,910] Trial 23 finished with value: 0.23113207547169812 and parameters: {'penalty': 'l2', 'C': 0.0034773460792848123}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,071] Trial 24 finished with value: 0.6320754716981132 and parameters: {'penalty': 'l2', 'C': 1843.297846434672}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,199] Trial 25 finished with value: 0.6698113207547169 and parameters: {'penalty': 'l2', 'C': 30.83171836504115}. Best is trial 16 with value: 0.6886792452830188.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:32,280] Trial 26 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 3.5059683210597683}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,326] Trial 27 finished with value: 0.6415094339622641 and parameters: {'penalty': 'l2', 'C': 0.7434164428425594}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,352] Trial 28 finished with value: 0.23113207547169812 and parameters: {'penalty': 'l2', 'C': 0.011833290333603362}. Best is trial 16 with value: 0.6886792452830188.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:32,433] Trial 29 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 29.88929148708229}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,571] Trial 30 finished with value: 0.6320754716981132 and parameters: {'penalty': 'l2', 'C': 1322.0243669571005}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,660] Trial 31 finished with value: 0.6886792452830188 and parameters: {'penalty': 'l2', 'C': 6.4482873685870175}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,722] Trial 32 finished with value: 0.6886792452830188 and parameters: {'penalty': 'l2', 'C': 4.065700102006385}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,803] Trial 33 finished with value: 0.6839622641509434 and parameters: {'penalty': 'l2', 'C': 3.2893232553312286}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,834] Trial 34 finished with value: 0.5660377358490566 and parameters: {'penalty': 'l2', 'C': 0.1765964956806838}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:32,862] Trial 35 finished with value: 0.2358490566037736 and parameters: {'penalty': 'l2', 'C': 0.03309765063040428}. Best is trial 16 with value: 0.6886792452830188.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:32,942] Trial 36 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 0.21481550906927138}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,116] Trial 37 finished with value: 0.6509433962264151 and parameters: {'penalty': 'l2', 'C': 400.5585993395585}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,256] Trial 38 finished with value: 0.6745283018867925 and parameters: {'penalty': 'l2', 'C': 60.44496458743557}. Best is trial 16 with value: 0.6886792452830188.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:33,341] Trial 39 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 3.2067121931893405}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,380] Trial 40 finished with value: 0.3915094339622642 and parameters: {'penalty': 'l2', 'C': 0.08338499708429888}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,472] Trial 41 finished with value: 0.6886792452830188 and parameters: {'penalty': 'l2', 'C': 5.158483401293687}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,558] Trial 42 finished with value: 0.6886792452830188 and parameters: {'penalty': 'l2', 'C': 5.846212446011164}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,608] Trial 43 finished with value: 0.6415094339622641 and parameters: {'penalty': 'l2', 'C': 0.5900499010774912}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,729] Trial 44 finished with value: 0.6462264150943396 and parameters: {'penalty': 'l2', 'C': 507.81666534299376}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,827] Trial 45 finished with value: 0.6698113207547169 and parameters: {'penalty': 'l2', 'C': 9.57459419627179}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:33,985] Trial 46 finished with value: 0.6650943396226415 and parameters: {'penalty': 'l2', 'C': 80.98336902251502}. Best is trial 16 with value: 0.6886792452830188.\n",
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-02-24 15:21:34,066] Trial 47 finished with value: 0.6037735849056604 and parameters: {'penalty': None, 'C': 5.109810356177191}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:34,122] Trial 48 finished with value: 0.6367924528301887 and parameters: {'penalty': 'l2', 'C': 1.015810148649463}. Best is trial 16 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:34,240] Trial 49 finished with value: 0.5990566037735849 and parameters: {'penalty': 'l2', 'C': 8928.997996675023}. Best is trial 16 with value: 0.6886792452830188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 5.449257421576762}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74        41\n",
      "           1       0.81      0.70      0.75        30\n",
      "           2       0.64      0.64      0.64        25\n",
      "           3       0.54      0.54      0.54        28\n",
      "           4       0.67      0.69      0.68        49\n",
      "           5       0.69      0.79      0.74        39\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.69      0.68      0.68       212\n",
      "weighted avg       0.69      0.69      0.69       212\n"
     ]
    }
   ],
   "source": [
    "# use optuna to optimize the hyperparameters of the logistic regression\n",
    "def objective_log(trial):\n",
    "    \n",
    "    # Define the hyperparameters to optimize\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', None])\n",
    "    \n",
    "    C = trial.suggest_float('C', 1e-5, 1e5, log=True)\n",
    "    \n",
    "    # Create the model\n",
    "    logisticRegr = LogisticRegression(penalty=penalty, C=C, max_iter=1000)\n",
    "    \n",
    "    # Fit the model\n",
    "    logisticRegr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the model\n",
    "    predictions = logisticRegr.predict(X_test)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return classification_report(y_test, predictions, output_dict=True , zero_division=0)['accuracy']\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the study\n",
    "study.optimize(objective_log, n_trials=50)\n",
    "\n",
    "#print the best parameters\n",
    "print(study.best_params)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "#run the logistic regression with the best parameters\n",
    "logisticRegr = LogisticRegression(penalty=best_params['penalty'], C=best_params['C'], max_iter=1000)\n",
    "\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is some improvement in the accuracy, from 0.64 to 0.69.\n",
    "\n",
    "Let's try to use other models to classify the words."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "126e8c7b9a855cc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We move on with support vector machine (SVM) to classify the words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9ebdead88b86cd1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83877787028355f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:13:06.771781300Z",
     "start_time": "2024-02-24T13:13:06.580383100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64        41\n",
      "           1       0.80      0.53      0.64        30\n",
      "           2       0.61      0.68      0.64        25\n",
      "           3       0.61      0.50      0.55        28\n",
      "           4       0.61      0.78      0.68        49\n",
      "           5       0.69      0.74      0.72        39\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.67      0.64      0.65       212\n",
      "weighted avg       0.66      0.66      0.65       212\n"
     ]
    }
   ],
   "source": [
    "# perform svm to classify the words\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is better than the logistic regression, but we can use optuna to optimize the hyperparameters of the SVM."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "633f63835d9adf17"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "497a5a463f8c7060",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:20:02.790017Z",
     "start_time": "2024-02-24T13:19:53.885018900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:19:53,884] A new study created in memory with name: no-name-a4c134aa-a83f-4501-ba4f-8a3dcfa7adc0\n",
      "[I 2024-02-24 15:19:54,053] Trial 0 finished with value: 0.23113207547169812 and parameters: {'C': 7.383911021345929, 'kernel': 'sigmoid', 'degree': 3, 'gamma': 'auto'}. Best is trial 0 with value: 0.23113207547169812.\n",
      "[I 2024-02-24 15:19:54,197] Trial 1 finished with value: 0.23113207547169812 and parameters: {'C': 1.9890683490482823e-05, 'kernel': 'linear', 'degree': 8, 'gamma': 'auto'}. Best is trial 0 with value: 0.23113207547169812.\n",
      "[I 2024-02-24 15:19:54,346] Trial 2 finished with value: 0.23113207547169812 and parameters: {'C': 3550.4214778294036, 'kernel': 'poly', 'degree': 3, 'gamma': 'auto'}. Best is trial 0 with value: 0.23113207547169812.\n",
      "[I 2024-02-24 15:19:54,470] Trial 3 finished with value: 0.6179245283018868 and parameters: {'C': 110.20925536699872, 'kernel': 'linear', 'degree': 8, 'gamma': 'auto'}. Best is trial 3 with value: 0.6179245283018868.\n",
      "[I 2024-02-24 15:19:54,594] Trial 4 finished with value: 0.6179245283018868 and parameters: {'C': 96132.6948418836, 'kernel': 'linear', 'degree': 6, 'gamma': 'auto'}. Best is trial 3 with value: 0.6179245283018868.\n",
      "[I 2024-02-24 15:19:54,758] Trial 5 finished with value: 0.23113207547169812 and parameters: {'C': 4.162669862745351, 'kernel': 'sigmoid', 'degree': 1, 'gamma': 'auto'}. Best is trial 3 with value: 0.6179245283018868.\n",
      "[I 2024-02-24 15:19:54,924] Trial 6 finished with value: 0.6226415094339622 and parameters: {'C': 14181.639427116339, 'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 6 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:19:55,125] Trial 7 finished with value: 0.23113207547169812 and parameters: {'C': 0.000714227098332259, 'kernel': 'rbf', 'degree': 7, 'gamma': 'scale'}. Best is trial 6 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:19:55,306] Trial 8 finished with value: 0.5424528301886793 and parameters: {'C': 5736.8860627836, 'kernel': 'sigmoid', 'degree': 1, 'gamma': 'scale'}. Best is trial 6 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:19:55,478] Trial 9 finished with value: 0.7075471698113207 and parameters: {'C': 2.1001201151035334, 'kernel': 'rbf', 'degree': 8, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:55,693] Trial 10 finished with value: 0.23113207547169812 and parameters: {'C': 0.017128951654045526, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:55,904] Trial 11 finished with value: 0.23113207547169812 and parameters: {'C': 0.07104499985558754, 'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:56,118] Trial 12 finished with value: 0.660377358490566 and parameters: {'C': 379.72430309992444, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:56,332] Trial 13 finished with value: 0.660377358490566 and parameters: {'C': 111.84215637525985, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:56,513] Trial 14 finished with value: 0.6745283018867925 and parameters: {'C': 96.87252138416453, 'kernel': 'poly', 'degree': 9, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:56,684] Trial 15 finished with value: 0.25 and parameters: {'C': 0.24304526263982656, 'kernel': 'poly', 'degree': 8, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:56,859] Trial 16 finished with value: 0.7028301886792453 and parameters: {'C': 6.538447411810787, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:57,029] Trial 17 finished with value: 0.23113207547169812 and parameters: {'C': 0.006839691248785011, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:57,204] Trial 18 finished with value: 0.7075471698113207 and parameters: {'C': 2.2605638839366704, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:57,380] Trial 19 finished with value: 0.7075471698113207 and parameters: {'C': 0.9804175647088382, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:57,590] Trial 20 finished with value: 0.23113207547169812 and parameters: {'C': 0.0007965561494511081, 'kernel': 'rbf', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:57,754] Trial 21 finished with value: 0.6933962264150944 and parameters: {'C': 0.8113606447126035, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:57,926] Trial 22 finished with value: 0.6556603773584906 and parameters: {'C': 0.6025301733048913, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:58,102] Trial 23 finished with value: 0.7028301886792453 and parameters: {'C': 11.743307474912259, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:58,279] Trial 24 finished with value: 0.23113207547169812 and parameters: {'C': 0.14924553602205515, 'kernel': 'poly', 'degree': 9, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:58,446] Trial 25 finished with value: 0.23113207547169812 and parameters: {'C': 0.022013565019391456, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:58,578] Trial 26 finished with value: 0.6462264150943396 and parameters: {'C': 1.0872301045000832, 'kernel': 'linear', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:58,707] Trial 27 finished with value: 0.6698113207547169 and parameters: {'C': 22.419104934162014, 'kernel': 'sigmoid', 'degree': 9, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:58,889] Trial 28 finished with value: 0.6981132075471698 and parameters: {'C': 2.8022078066007134, 'kernel': 'poly', 'degree': 8, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:59,066] Trial 29 finished with value: 0.23113207547169812 and parameters: {'C': 0.004926943883776418, 'kernel': 'sigmoid', 'degree': 4, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:59,284] Trial 30 finished with value: 0.660377358490566 and parameters: {'C': 644.8398077220763, 'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:59,462] Trial 31 finished with value: 0.7028301886792453 and parameters: {'C': 24.71711521872377, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:59,640] Trial 32 finished with value: 0.6933962264150944 and parameters: {'C': 3.9934573243513034, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:59,817] Trial 33 finished with value: 0.7028301886792453 and parameters: {'C': 1.0906834615388157, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:19:59,976] Trial 34 finished with value: 0.23113207547169812 and parameters: {'C': 0.07361551173756163, 'kernel': 'poly', 'degree': 8, 'gamma': 'auto'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:00,104] Trial 35 finished with value: 0.6415094339622641 and parameters: {'C': 23.805763955725133, 'kernel': 'linear', 'degree': 6, 'gamma': 'auto'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:00,290] Trial 36 finished with value: 0.6981132075471698 and parameters: {'C': 5.796600435613268, 'kernel': 'poly', 'degree': 8, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:00,442] Trial 37 finished with value: 0.6179245283018868 and parameters: {'C': 0.35466519207540703, 'kernel': 'linear', 'degree': 5, 'gamma': 'auto'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:00,623] Trial 38 finished with value: 0.6933962264150944 and parameters: {'C': 74.69585696922606, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:00,792] Trial 39 finished with value: 0.23113207547169812 and parameters: {'C': 2.3131700578309665e-05, 'kernel': 'sigmoid', 'degree': 6, 'gamma': 'auto'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:01,004] Trial 40 finished with value: 0.660377358490566 and parameters: {'C': 907.244130009888, 'kernel': 'rbf', 'degree': 9, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:01,181] Trial 41 finished with value: 0.7028301886792453 and parameters: {'C': 13.441675030610867, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:01,362] Trial 42 finished with value: 0.6933962264150944 and parameters: {'C': 3.0020838213398, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 9 with value: 0.7075471698113207.\n",
      "[I 2024-02-24 15:20:01,541] Trial 43 finished with value: 0.7122641509433962 and parameters: {'C': 1.8281599977692966, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 43 with value: 0.7122641509433962.\n",
      "[I 2024-02-24 15:20:01,714] Trial 44 finished with value: 0.7028301886792453 and parameters: {'C': 1.3588251763994328, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 43 with value: 0.7122641509433962.\n",
      "[I 2024-02-24 15:20:01,928] Trial 45 finished with value: 0.2358490566037736 and parameters: {'C': 0.1297649187128465, 'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 43 with value: 0.7122641509433962.\n",
      "[I 2024-02-24 15:20:02,102] Trial 46 finished with value: 0.23113207547169812 and parameters: {'C': 0.034732156018254634, 'kernel': 'poly', 'degree': 8, 'gamma': 'scale'}. Best is trial 43 with value: 0.7122641509433962.\n",
      "[I 2024-02-24 15:20:02,240] Trial 47 finished with value: 0.6179245283018868 and parameters: {'C': 55.85404826206339, 'kernel': 'linear', 'degree': 7, 'gamma': 'auto'}. Best is trial 43 with value: 0.7122641509433962.\n",
      "[I 2024-02-24 15:20:02,455] Trial 48 finished with value: 0.660377358490566 and parameters: {'C': 201.43245042032098, 'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 43 with value: 0.7122641509433962.\n",
      "[I 2024-02-24 15:20:02,611] Trial 49 finished with value: 0.6367924528301887 and parameters: {'C': 0.2883390876820827, 'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 43 with value: 0.7122641509433962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        41\n",
      "           1       0.83      0.67      0.74        30\n",
      "           2       0.74      0.80      0.77        25\n",
      "           3       0.65      0.61      0.63        28\n",
      "           4       0.69      0.71      0.70        49\n",
      "           5       0.73      0.77      0.75        39\n",
      "\n",
      "    accuracy                           0.71       212\n",
      "   macro avg       0.72      0.71      0.71       212\n",
      "weighted avg       0.72      0.71      0.71       212\n"
     ]
    }
   ],
   "source": [
    "# Create an optuna function to optimize the hyperparameters of the SVM\n",
    "def objective_svm(trial):\n",
    "    \n",
    "    # Define the hyperparameters to optimize\n",
    "    C = trial.suggest_float('C', 1e-5, 1e5, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    degree = trial.suggest_int('degree', 1, 10)\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    \n",
    "    # Create the model\n",
    "    svm = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the model\n",
    "    predictions = svm.predict(X_test)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return classification_report(y_test, predictions,  output_dict=True, zero_division=0)['accuracy']\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the study\n",
    "study.optimize(objective_svm, n_trials=50)\n",
    "\n",
    "# print the classification report with the best parameters\n",
    "best_params_svm = study.best_params\n",
    "\n",
    "svm = SVC(C=best_params_svm['C'], kernel=best_params_svm['kernel'], degree=best_params_svm['degree'], gamma=best_params_svm['gamma'])\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a significant improvement of the original accuracy of 0.66 to 0.71."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b641f383e916b672"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We move on with stochastic gradient descent (SGD) to classify the words with the default parameters."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97e455b52233b5d1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c631bb16de3b9e97",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:13:37.893644300Z",
     "start_time": "2024-02-24T13:13:37.730044600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72        41\n",
      "           1       0.81      0.70      0.75        30\n",
      "           2       0.54      0.80      0.65        25\n",
      "           3       0.61      0.50      0.55        28\n",
      "           4       0.74      0.71      0.73        49\n",
      "           5       0.68      0.69      0.68        39\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.69      0.69      0.68       212\n",
      "weighted avg       0.70      0.69      0.69       212\n"
     ]
    }
   ],
   "source": [
    "#perform SGD to classify the words\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "predictions = sgd.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy is 0.69, which is not very high. We can use optuna to optimize the hyperparameters of the SGD."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10db58d8759f0db"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d739e8649ef4747",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:21:18.089593Z",
     "start_time": "2024-02-24T13:20:44.057446500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:20:44,057] A new study created in memory with name: no-name-e63504f9-09aa-4ebc-b06d-32a99c147384\n",
      "[I 2024-02-24 15:20:44,973] Trial 0 finished with value: 0.6179245283018868 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 8.869158359672956e-05, 'learning_rate': 'adaptive', 'eta0': 0.006292980805760247, 'l1_ratio': 0.7879974154984328}. Best is trial 0 with value: 0.6179245283018868.\n",
      "[I 2024-02-24 15:20:45,108] Trial 1 finished with value: 0.23113207547169812 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 0.004898312514319803, 'learning_rate': 'invscaling', 'eta0': 0.0005620474353849702, 'l1_ratio': 0.7360326034538617}. Best is trial 0 with value: 0.6179245283018868.\n",
      "[I 2024-02-24 15:20:45,753] Trial 2 finished with value: 0.6226415094339622 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 0.0003702331750030169, 'learning_rate': 'optimal', 'eta0': 1.1230655325593459e-05, 'l1_ratio': 0.43099553993029105}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:45,896] Trial 3 finished with value: 0.5188679245283019 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 0.00030819633528699077, 'learning_rate': 'constant', 'eta0': 0.028025263367847702, 'l1_ratio': 0.3875642760645881}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:46,768] Trial 4 finished with value: 0.23113207547169812 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 0.0933456906570281, 'learning_rate': 'adaptive', 'eta0': 0.00026840817274505793, 'l1_ratio': 0.43669371210814034}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:47,049] Trial 5 finished with value: 0.23113207547169812 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 0.05236658701885484, 'learning_rate': 'optimal', 'eta0': 0.0003113937252058365, 'l1_ratio': 0.47639074675499116}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:47,543] Trial 6 finished with value: 0.23113207547169812 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 3.7713441916214135e-06, 'learning_rate': 'invscaling', 'eta0': 0.0019889750233825693, 'l1_ratio': 0.6350176067222667}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:47,975] Trial 7 finished with value: 0.6226415094339622 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.000781250297715185, 'learning_rate': 'optimal', 'eta0': 0.0001563349240060829, 'l1_ratio': 0.8173900361277339}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:48,193] Trial 8 finished with value: 0.5754716981132075 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.0676789996810588, 'learning_rate': 'constant', 'eta0': 0.0012169018556830488, 'l1_ratio': 0.7792127516095392}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:49,273] Trial 9 finished with value: 0.23113207547169812 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 0.009432094017613682, 'learning_rate': 'invscaling', 'eta0': 0.001727768028436311, 'l1_ratio': 0.6326769783254411}. Best is trial 2 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:20:50,014] Trial 10 finished with value: 0.660377358490566 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.2134818657540837e-05, 'learning_rate': 'optimal', 'eta0': 1.0734141927426523e-05, 'l1_ratio': 0.08954376897925409}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:50,871] Trial 11 finished with value: 0.6273584905660378 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 8.500192955033123e-06, 'learning_rate': 'optimal', 'eta0': 1.0589960388735084e-05, 'l1_ratio': 0.08918158248337482}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:51,740] Trial 12 finished with value: 0.6462264150943396 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 2.6832261156318374e-06, 'learning_rate': 'optimal', 'eta0': 1.1826662744157275e-05, 'l1_ratio': 0.06197093065363637}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:52,558] Trial 13 finished with value: 0.6037735849056604 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.08834153594978e-06, 'learning_rate': 'optimal', 'eta0': 4.8053065825285105e-05, 'l1_ratio': 0.026627771963838538}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:53,290] Trial 14 finished with value: 0.6226415094339622 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.8856251541688072e-05, 'learning_rate': 'optimal', 'eta0': 5.1261149721979155e-05, 'l1_ratio': 0.21555792254263076}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:53,561] Trial 15 finished with value: 0.660377358490566 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 1.4796619010893935e-05, 'learning_rate': 'optimal', 'eta0': 5.232933903952594e-05, 'l1_ratio': 0.24230888626093564}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:53,798] Trial 16 finished with value: 0.5754716981132075 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 2.1851189663453462e-05, 'learning_rate': 'optimal', 'eta0': 7.866520687512573e-05, 'l1_ratio': 0.27000871097416684}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:54,700] Trial 17 finished with value: 0.23113207547169812 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 5.801773407279978e-05, 'learning_rate': 'adaptive', 'eta0': 3.142928803578002e-05, 'l1_ratio': 0.9751902829123611}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:55,024] Trial 18 finished with value: 0.5849056603773585 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 8.817666709253591e-06, 'learning_rate': 'constant', 'eta0': 2.664898232731697e-05, 'l1_ratio': 0.19993393499723824}. Best is trial 10 with value: 0.660377358490566.\n",
      "[I 2024-02-24 15:20:55,209] Trial 19 finished with value: 0.6839622641509434 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.0001337233571249784, 'learning_rate': 'optimal', 'eta0': 0.07616596316693416, 'l1_ratio': 0.30846069705099327}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:55,368] Trial 20 finished with value: 0.6698113207547169 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.00016100953120571374, 'learning_rate': 'optimal', 'eta0': 0.08253760195693005, 'l1_ratio': 0.344628075458683}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:55,550] Trial 21 finished with value: 0.6462264150943396 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.0001536146805305894, 'learning_rate': 'optimal', 'eta0': 0.06928422277405617, 'l1_ratio': 0.37181145117863956}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:55,692] Trial 22 finished with value: 0.6179245283018868 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.000877240734675964, 'learning_rate': 'optimal', 'eta0': 0.013849290548148607, 'l1_ratio': 0.1478182536623123}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:55,914] Trial 23 finished with value: 0.6698113207547169 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 5.09063853971021e-05, 'learning_rate': 'optimal', 'eta0': 0.06586373223798211, 'l1_ratio': 0.3180426576805092}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:56,026] Trial 24 finished with value: 0.6320754716981132 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.0028110222701048957, 'learning_rate': 'optimal', 'eta0': 0.09539541645082296, 'l1_ratio': 0.3282265504869037}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:56,225] Trial 25 finished with value: 0.6745283018867925 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 6.597771999013005e-05, 'learning_rate': 'optimal', 'eta0': 0.03509163992652497, 'l1_ratio': 0.563385508765512}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:56,276] Trial 26 finished with value: 0.6132075471698113 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 0.00018334485909061706, 'learning_rate': 'invscaling', 'eta0': 0.027237499584022648, 'l1_ratio': 0.5503391526664274}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:56,336] Trial 27 finished with value: 0.6462264150943396 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 0.0010114100288518635, 'learning_rate': 'constant', 'eta0': 0.0044595450387758554, 'l1_ratio': 0.5680599464454225}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:56,999] Trial 28 finished with value: 0.6745283018867925 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.00011008558580386672, 'learning_rate': 'adaptive', 'eta0': 0.03845807665277665, 'l1_ratio': 0.5417320744404739}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:20:58,058] Trial 29 finished with value: 0.6650943396226415 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 6.759106587718946e-05, 'learning_rate': 'adaptive', 'eta0': 0.0074803505793455205, 'l1_ratio': 0.6811020859249395}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:21:00,790] Trial 30 finished with value: 0.6650943396226415 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 0.0004541132455801899, 'learning_rate': 'adaptive', 'eta0': 0.03194644186425191, 'l1_ratio': 0.514805235112823}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:21:01,475] Trial 31 finished with value: 0.6792452830188679 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.00014228576129773378, 'learning_rate': 'adaptive', 'eta0': 0.045103993079661606, 'l1_ratio': 0.5786041034679642}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:21:02,150] Trial 32 finished with value: 0.6839622641509434 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 8.749804068204586e-05, 'learning_rate': 'adaptive', 'eta0': 0.014351639449111647, 'l1_ratio': 0.5902337177377446}. Best is trial 19 with value: 0.6839622641509434.\n",
      "[I 2024-02-24 15:21:02,952] Trial 33 finished with value: 0.6886792452830188 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 2.8205853574764996e-05, 'learning_rate': 'adaptive', 'eta0': 0.01332367456137524, 'l1_ratio': 0.6090438043687832}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:03,637] Trial 34 finished with value: 0.6839622641509434 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 3.191083557991246e-05, 'learning_rate': 'adaptive', 'eta0': 0.014116772689209928, 'l1_ratio': 0.8747229375806669}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:05,128] Trial 35 finished with value: 0.6839622641509434 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 3.642473746679224e-05, 'learning_rate': 'adaptive', 'eta0': 0.013597804739891832, 'l1_ratio': 0.8617102127981332}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:05,888] Trial 36 finished with value: 0.660377358490566 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 5.214519730209483e-06, 'learning_rate': 'adaptive', 'eta0': 0.003406765736793633, 'l1_ratio': 0.9875768284460676}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:07,707] Trial 37 finished with value: 0.6698113207547169 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 0.0002812144917788178, 'learning_rate': 'adaptive', 'eta0': 0.017111246374833182, 'l1_ratio': 0.709252851817552}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:07,872] Trial 38 finished with value: 0.6415094339622641 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 2.5338445765170954e-05, 'learning_rate': 'adaptive', 'eta0': 0.007771054148935864, 'l1_ratio': 0.44963877725527135}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:08,650] Trial 39 finished with value: 0.6273584905660378 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.0005149389933296016, 'learning_rate': 'adaptive', 'eta0': 0.0007619221632273141, 'l1_ratio': 0.8739181856829258}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:09,109] Trial 40 finished with value: 0.6650943396226415 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.001741470818072404, 'learning_rate': 'adaptive', 'eta0': 0.019742000281575637, 'l1_ratio': 0.6361758591084703}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:10,678] Trial 41 finished with value: 0.6839622641509434 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 2.738377986645066e-05, 'learning_rate': 'adaptive', 'eta0': 0.011763767743929125, 'l1_ratio': 0.9059077334606961}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:12,368] Trial 42 finished with value: 0.6462264150943396 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 3.696781395599291e-05, 'learning_rate': 'adaptive', 'eta0': 0.0032373488093907473, 'l1_ratio': 0.7756826081087623}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:13,787] Trial 43 finished with value: 0.6745283018867925 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 1.7619260861743863e-05, 'learning_rate': 'adaptive', 'eta0': 0.009634773309241113, 'l1_ratio': 0.8418569765295396}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:14,063] Trial 44 finished with value: 0.38207547169811323 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 4.267021279783975e-05, 'learning_rate': 'invscaling', 'eta0': 0.023623758014035472, 'l1_ratio': 0.7382857815083153}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:15,582] Trial 45 finished with value: 0.6698113207547169 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 8.71886759603934e-05, 'learning_rate': 'adaptive', 'eta0': 0.004727427335175098, 'l1_ratio': 0.9085586901344004}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:15,980] Trial 46 finished with value: 0.6226415094339622 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 0.0002851553620832034, 'learning_rate': 'adaptive', 'eta0': 0.0021533770569448756, 'l1_ratio': 0.4120062129971176}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:16,347] Trial 47 finished with value: 0.6556603773584906 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 5.6879904396064e-06, 'learning_rate': 'constant', 'eta0': 0.051355068448195346, 'l1_ratio': 0.6542660484031765}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:17,061] Trial 48 finished with value: 0.6037735849056604 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 1.1059381974556579e-05, 'learning_rate': 'adaptive', 'eta0': 0.0003783770991291407, 'l1_ratio': 0.48198437885271367}. Best is trial 33 with value: 0.6886792452830188.\n",
      "[I 2024-02-24 15:21:17,443] Trial 49 finished with value: 0.23113207547169812 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 0.0310904627014616, 'learning_rate': 'invscaling', 'eta0': 0.01569669752053049, 'l1_ratio': 0.8069840005321073}. Best is trial 33 with value: 0.6886792452830188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.73        41\n",
      "           1       0.81      0.73      0.77        30\n",
      "           2       0.64      0.72      0.68        25\n",
      "           3       0.52      0.54      0.53        28\n",
      "           4       0.74      0.69      0.72        49\n",
      "           5       0.65      0.77      0.71        39\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.69      0.69      0.69       212\n",
      "weighted avg       0.70      0.69      0.69       212\n"
     ]
    }
   ],
   "source": [
    "# Create an optuna function to optimize the hyperparameters of the SGD\n",
    "def objective_sgd(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    loss = trial.suggest_categorical('loss', ['hinge', 'log_loss', 'squared_hinge', 'perceptron'])\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1', 'elasticnet'])\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
    "    eta0 = trial.suggest_float('eta0', 1e-5, 1e-1, log=True)  # Only relevant for certain learning rates\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "    \n",
    "    # Create the model\n",
    "    sgd = SGDClassifier(loss=loss, penalty=penalty, alpha=alpha, learning_rate=learning_rate, eta0=eta0, l1_ratio=l1_ratio)\n",
    "    \n",
    "    # Fit the model\n",
    "    sgd.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the model\n",
    "    predictions = sgd.predict(X_test)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return classification_report(y_test, predictions, output_dict=True, zero_division=0)['accuracy']\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the study\n",
    "study.optimize(objective_sgd, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "#create the classification with the best parameters\n",
    "sgd = SGDClassifier(loss=best_params['loss'], penalty=best_params['penalty'], alpha=best_params['alpha'], learning_rate=best_params['learning_rate'], eta0=best_params['eta0'], l1_ratio=best_params['l1_ratio'])\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "predictions = sgd.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy is 0.69, which is the same as the default parameters with some small improvements in the macro avg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7d7690bdbea0ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Continue with random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfd86905129e0dec"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc6415bd68d0ddd6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:09:06.383474700Z",
     "start_time": "2024-02-24T13:09:04.992803300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        41\n",
      "           1       0.65      0.37      0.47        30\n",
      "           2       0.58      0.60      0.59        25\n",
      "           3       0.54      0.46      0.50        28\n",
      "           4       0.56      0.73      0.64        49\n",
      "           5       0.62      0.64      0.63        39\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.59      0.57      0.57       212\n",
      "weighted avg       0.59      0.58      0.58       212\n"
     ]
    }
   ],
   "source": [
    "# Perform random forest to classify the words\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "the value of the accuracy is 0.58 is significantly lower than the other models, lets check if we can optimize the hyperparameters of the random forest."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b027c41895582f"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dec92db426865cb1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:24:28.184810100Z",
     "start_time": "2024-02-24T13:23:31.794061900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:23:31,794] A new study created in memory with name: no-name-3a35ac53-d06f-4180-bcf1-cfa16d65a5f4\n",
      "[I 2024-02-24 15:23:34,453] Trial 0 finished with value: 0.589622641509434 and parameters: {'n_estimators': 137, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 13}. Best is trial 0 with value: 0.589622641509434.\n",
      "[I 2024-02-24 15:23:34,952] Trial 1 finished with value: 0.5707547169811321 and parameters: {'n_estimators': 48, 'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 22}. Best is trial 0 with value: 0.589622641509434.\n",
      "[I 2024-02-24 15:23:37,513] Trial 2 finished with value: 0.5943396226415094 and parameters: {'n_estimators': 190, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 18}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:37,683] Trial 3 finished with value: 0.44339622641509435 and parameters: {'n_estimators': 6, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 38}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:40,670] Trial 4 finished with value: 0.5801886792452831 and parameters: {'n_estimators': 148, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 39}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:44,892] Trial 5 finished with value: 0.5849056603773585 and parameters: {'n_estimators': 189, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': 26}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:47,601] Trial 6 finished with value: 0.5849056603773585 and parameters: {'n_estimators': 79, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 50}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:49,130] Trial 7 finished with value: 0.5660377358490566 and parameters: {'n_estimators': 103, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': 44}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:49,642] Trial 8 finished with value: 0.5566037735849056 and parameters: {'n_estimators': 46, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 13}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:49,857] Trial 9 finished with value: 0.42924528301886794 and parameters: {'n_estimators': 27, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 24}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:50,186] Trial 10 finished with value: 0.5566037735849056 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 1}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:50,812] Trial 11 finished with value: 0.5754716981132075 and parameters: {'n_estimators': 148, 'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 8}. Best is trial 2 with value: 0.5943396226415094.\n",
      "[I 2024-02-24 15:23:51,911] Trial 12 finished with value: 0.6179245283018868 and parameters: {'n_estimators': 154, 'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 12}. Best is trial 12 with value: 0.6179245283018868.\n",
      "[I 2024-02-24 15:23:53,512] Trial 13 finished with value: 0.6226415094339622 and parameters: {'n_estimators': 170, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 18}. Best is trial 13 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:23:55,383] Trial 14 finished with value: 0.589622641509434 and parameters: {'n_estimators': 119, 'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 32}. Best is trial 13 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:23:55,956] Trial 15 finished with value: 0.5566037735849056 and parameters: {'n_estimators': 170, 'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 4}. Best is trial 13 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:23:57,262] Trial 16 finished with value: 0.6226415094339622 and parameters: {'n_estimators': 169, 'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 14}. Best is trial 13 with value: 0.6226415094339622.\n",
      "[I 2024-02-24 15:23:58,740] Trial 17 finished with value: 0.6320754716981132 and parameters: {'n_estimators': 168, 'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 18}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:00,347] Trial 18 finished with value: 0.6226415094339622 and parameters: {'n_estimators': 117, 'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 30}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:01,122] Trial 19 finished with value: 0.5660377358490566 and parameters: {'n_estimators': 83, 'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 19}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:03,253] Trial 20 finished with value: 0.6037735849056604 and parameters: {'n_estimators': 169, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 29}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:04,763] Trial 21 finished with value: 0.6037735849056604 and parameters: {'n_estimators': 172, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 17}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:05,444] Trial 22 finished with value: 0.5849056603773585 and parameters: {'n_estimators': 132, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 8}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:07,294] Trial 23 finished with value: 0.6273584905660378 and parameters: {'n_estimators': 177, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 21}. Best is trial 17 with value: 0.6320754716981132.\n",
      "[I 2024-02-24 15:24:09,124] Trial 24 finished with value: 0.6415094339622641 and parameters: {'n_estimators': 189, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 21}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:11,092] Trial 25 finished with value: 0.6273584905660378 and parameters: {'n_estimators': 188, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 23}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:13,761] Trial 26 finished with value: 0.6226415094339622 and parameters: {'n_estimators': 196, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 33}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:15,743] Trial 27 finished with value: 0.6084905660377359 and parameters: {'n_estimators': 158, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 27}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:17,427] Trial 28 finished with value: 0.6367924528301887 and parameters: {'n_estimators': 183, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 21}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:18,592] Trial 29 finished with value: 0.5660377358490566 and parameters: {'n_estimators': 134, 'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 9}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:19,781] Trial 30 finished with value: 0.6084905660377359 and parameters: {'n_estimators': 179, 'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 15}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:21,525] Trial 31 finished with value: 0.5849056603773585 and parameters: {'n_estimators': 182, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 21}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:23,168] Trial 32 finished with value: 0.6273584905660378 and parameters: {'n_estimators': 159, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 21}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:25,258] Trial 33 finished with value: 0.6273584905660378 and parameters: {'n_estimators': 198, 'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 25}. Best is trial 24 with value: 0.6415094339622641.\n",
      "[I 2024-02-24 15:24:26,411] Trial 34 finished with value: 0.589622641509434 and parameters: {'n_estimators': 142, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 20}. Best is trial 24 with value: 0.6415094339622641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62        41\n",
      "           1       0.93      0.43      0.59        30\n",
      "           2       0.62      0.52      0.57        25\n",
      "           3       0.55      0.39      0.46        28\n",
      "           4       0.51      0.71      0.60        49\n",
      "           5       0.63      0.74      0.68        39\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.64      0.57      0.59       212\n",
      "weighted avg       0.63      0.60      0.59       212\n"
     ]
    }
   ],
   "source": [
    "# Create an optuna function to optimize the hyperparameters of the random forest\n",
    "def objective_rf(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_int('max_features', 1, 50)\n",
    "    \n",
    "    # Create the model\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_features=max_features)\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the model\n",
    "    predictions = rf.predict(X_test)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return classification_report(y_test, predictions, output_dict=True, zero_division=0)['accuracy']\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the study\n",
    "study.optimize(objective_rf, n_trials=35)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Create the random forest with the best parameters\n",
    "rf = RandomForestClassifier(n_estimators=best_params['n_estimators'], criterion=best_params['criterion'], max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split'], min_samples_leaf=best_params['min_samples_leaf'], max_features=best_params['max_features'])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "That was not much of an improvement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e332b3532c8ffb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Continue with xgboost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5418a05d87218e8f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1245365777b8cf43",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:10:12.943406700Z",
     "start_time": "2024-02-24T13:10:11.825072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48        41\n",
      "           1       0.60      0.30      0.40        30\n",
      "           2       0.49      0.68      0.57        25\n",
      "           3       0.47      0.32      0.38        28\n",
      "           4       0.52      0.63      0.57        49\n",
      "           5       0.60      0.62      0.61        39\n",
      "\n",
      "    accuracy                           0.52       212\n",
      "   macro avg       0.52      0.51      0.50       212\n",
      "weighted avg       0.52      0.52      0.51       212\n"
     ]
    }
   ],
   "source": [
    "#perform xgboost to classify the words\n",
    "xg_reg = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "predictions = xg_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "these are the lowest results so far, moving on with catboost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1090a0b2113af6d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1967b333bb39a5de",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:10:39.981640700Z",
     "start_time": "2024-02-24T13:10:12.943406700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.062714\n",
      "0:\tlearn: 1.7636051\ttotal: 52.5ms\tremaining: 52.5s\n",
      "1:\tlearn: 1.7363956\ttotal: 82.6ms\tremaining: 41.2s\n",
      "2:\tlearn: 1.7107153\ttotal: 111ms\tremaining: 36.8s\n",
      "3:\tlearn: 1.6845616\ttotal: 140ms\tremaining: 34.8s\n",
      "4:\tlearn: 1.6581248\ttotal: 169ms\tremaining: 33.6s\n",
      "5:\tlearn: 1.6343432\ttotal: 197ms\tremaining: 32.6s\n",
      "6:\tlearn: 1.6110658\ttotal: 224ms\tremaining: 31.8s\n",
      "7:\tlearn: 1.5885057\ttotal: 253ms\tremaining: 31.4s\n",
      "8:\tlearn: 1.5687516\ttotal: 283ms\tremaining: 31.2s\n",
      "9:\tlearn: 1.5482964\ttotal: 312ms\tremaining: 30.9s\n",
      "10:\tlearn: 1.5271912\ttotal: 341ms\tremaining: 30.7s\n",
      "11:\tlearn: 1.5059656\ttotal: 371ms\tremaining: 30.5s\n",
      "12:\tlearn: 1.4851258\ttotal: 400ms\tremaining: 30.4s\n",
      "13:\tlearn: 1.4649072\ttotal: 429ms\tremaining: 30.2s\n",
      "14:\tlearn: 1.4459413\ttotal: 459ms\tremaining: 30.1s\n",
      "15:\tlearn: 1.4262279\ttotal: 487ms\tremaining: 29.9s\n",
      "16:\tlearn: 1.4079109\ttotal: 517ms\tremaining: 29.9s\n",
      "17:\tlearn: 1.3894144\ttotal: 546ms\tremaining: 29.8s\n",
      "18:\tlearn: 1.3725280\ttotal: 576ms\tremaining: 29.7s\n",
      "19:\tlearn: 1.3555491\ttotal: 605ms\tremaining: 29.6s\n",
      "20:\tlearn: 1.3399634\ttotal: 634ms\tremaining: 29.6s\n",
      "21:\tlearn: 1.3244265\ttotal: 663ms\tremaining: 29.5s\n",
      "22:\tlearn: 1.3088749\ttotal: 692ms\tremaining: 29.4s\n",
      "23:\tlearn: 1.2925489\ttotal: 722ms\tremaining: 29.4s\n",
      "24:\tlearn: 1.2765590\ttotal: 751ms\tremaining: 29.3s\n",
      "25:\tlearn: 1.2619167\ttotal: 780ms\tremaining: 29.2s\n",
      "26:\tlearn: 1.2483372\ttotal: 808ms\tremaining: 29.1s\n",
      "27:\tlearn: 1.2335094\ttotal: 836ms\tremaining: 29s\n",
      "28:\tlearn: 1.2183669\ttotal: 864ms\tremaining: 28.9s\n",
      "29:\tlearn: 1.2039999\ttotal: 893ms\tremaining: 28.9s\n",
      "30:\tlearn: 1.1906276\ttotal: 921ms\tremaining: 28.8s\n",
      "31:\tlearn: 1.1763865\ttotal: 949ms\tremaining: 28.7s\n",
      "32:\tlearn: 1.1658275\ttotal: 975ms\tremaining: 28.6s\n",
      "33:\tlearn: 1.1539135\ttotal: 1s\tremaining: 28.5s\n",
      "34:\tlearn: 1.1406627\ttotal: 1.03s\tremaining: 28.5s\n",
      "35:\tlearn: 1.1284236\ttotal: 1.06s\tremaining: 28.4s\n",
      "36:\tlearn: 1.1166777\ttotal: 1.09s\tremaining: 28.3s\n",
      "37:\tlearn: 1.1051373\ttotal: 1.12s\tremaining: 28.3s\n",
      "38:\tlearn: 1.0936723\ttotal: 1.14s\tremaining: 28.2s\n",
      "39:\tlearn: 1.0811609\ttotal: 1.17s\tremaining: 28.1s\n",
      "40:\tlearn: 1.0701745\ttotal: 1.2s\tremaining: 28.1s\n",
      "41:\tlearn: 1.0588506\ttotal: 1.23s\tremaining: 28.1s\n",
      "42:\tlearn: 1.0485873\ttotal: 1.26s\tremaining: 28s\n",
      "43:\tlearn: 1.0386259\ttotal: 1.29s\tremaining: 28s\n",
      "44:\tlearn: 1.0279225\ttotal: 1.31s\tremaining: 27.9s\n",
      "45:\tlearn: 1.0168393\ttotal: 1.34s\tremaining: 27.9s\n",
      "46:\tlearn: 1.0069771\ttotal: 1.37s\tremaining: 27.8s\n",
      "47:\tlearn: 0.9962842\ttotal: 1.4s\tremaining: 27.8s\n",
      "48:\tlearn: 0.9868261\ttotal: 1.43s\tremaining: 27.7s\n",
      "49:\tlearn: 0.9772582\ttotal: 1.46s\tremaining: 27.7s\n",
      "50:\tlearn: 0.9674624\ttotal: 1.49s\tremaining: 27.7s\n",
      "51:\tlearn: 0.9571870\ttotal: 1.52s\tremaining: 27.6s\n",
      "52:\tlearn: 0.9473854\ttotal: 1.55s\tremaining: 27.6s\n",
      "53:\tlearn: 0.9369160\ttotal: 1.58s\tremaining: 27.6s\n",
      "54:\tlearn: 0.9289207\ttotal: 1.61s\tremaining: 27.6s\n",
      "55:\tlearn: 0.9208317\ttotal: 1.64s\tremaining: 27.6s\n",
      "56:\tlearn: 0.9115129\ttotal: 1.67s\tremaining: 27.6s\n",
      "57:\tlearn: 0.9029752\ttotal: 1.69s\tremaining: 27.5s\n",
      "58:\tlearn: 0.8963074\ttotal: 1.72s\tremaining: 27.4s\n",
      "59:\tlearn: 0.8882198\ttotal: 1.75s\tremaining: 27.4s\n",
      "60:\tlearn: 0.8793749\ttotal: 1.78s\tremaining: 27.4s\n",
      "61:\tlearn: 0.8718984\ttotal: 1.81s\tremaining: 27.4s\n",
      "62:\tlearn: 0.8645727\ttotal: 1.84s\tremaining: 27.3s\n",
      "63:\tlearn: 0.8562481\ttotal: 1.87s\tremaining: 27.3s\n",
      "64:\tlearn: 0.8485079\ttotal: 1.9s\tremaining: 27.3s\n",
      "65:\tlearn: 0.8404742\ttotal: 1.93s\tremaining: 27.3s\n",
      "66:\tlearn: 0.8333479\ttotal: 1.96s\tremaining: 27.2s\n",
      "67:\tlearn: 0.8262102\ttotal: 1.98s\tremaining: 27.2s\n",
      "68:\tlearn: 0.8190014\ttotal: 2.01s\tremaining: 27.2s\n",
      "69:\tlearn: 0.8127273\ttotal: 2.04s\tremaining: 27.1s\n",
      "70:\tlearn: 0.8043730\ttotal: 2.07s\tremaining: 27.1s\n",
      "71:\tlearn: 0.7970811\ttotal: 2.1s\tremaining: 27.1s\n",
      "72:\tlearn: 0.7900727\ttotal: 2.13s\tremaining: 27s\n",
      "73:\tlearn: 0.7833744\ttotal: 2.16s\tremaining: 27s\n",
      "74:\tlearn: 0.7766792\ttotal: 2.18s\tremaining: 26.9s\n",
      "75:\tlearn: 0.7699087\ttotal: 2.21s\tremaining: 26.9s\n",
      "76:\tlearn: 0.7635542\ttotal: 2.24s\tremaining: 26.8s\n",
      "77:\tlearn: 0.7571991\ttotal: 2.27s\tremaining: 26.8s\n",
      "78:\tlearn: 0.7506490\ttotal: 2.29s\tremaining: 26.8s\n",
      "79:\tlearn: 0.7444671\ttotal: 2.32s\tremaining: 26.7s\n",
      "80:\tlearn: 0.7387521\ttotal: 2.35s\tremaining: 26.7s\n",
      "81:\tlearn: 0.7323210\ttotal: 2.38s\tremaining: 26.6s\n",
      "82:\tlearn: 0.7266680\ttotal: 2.4s\tremaining: 26.6s\n",
      "83:\tlearn: 0.7210214\ttotal: 2.43s\tremaining: 26.5s\n",
      "84:\tlearn: 0.7145515\ttotal: 2.46s\tremaining: 26.5s\n",
      "85:\tlearn: 0.7087015\ttotal: 2.48s\tremaining: 26.4s\n",
      "86:\tlearn: 0.7040907\ttotal: 2.51s\tremaining: 26.4s\n",
      "87:\tlearn: 0.6977572\ttotal: 2.54s\tremaining: 26.3s\n",
      "88:\tlearn: 0.6917385\ttotal: 2.57s\tremaining: 26.3s\n",
      "89:\tlearn: 0.6851419\ttotal: 2.6s\tremaining: 26.3s\n",
      "90:\tlearn: 0.6798325\ttotal: 2.63s\tremaining: 26.2s\n",
      "91:\tlearn: 0.6750023\ttotal: 2.65s\tremaining: 26.2s\n",
      "92:\tlearn: 0.6696143\ttotal: 2.68s\tremaining: 26.2s\n",
      "93:\tlearn: 0.6640607\ttotal: 2.71s\tremaining: 26.1s\n",
      "94:\tlearn: 0.6594105\ttotal: 2.74s\tremaining: 26.1s\n",
      "95:\tlearn: 0.6537413\ttotal: 2.77s\tremaining: 26.1s\n",
      "96:\tlearn: 0.6483076\ttotal: 2.8s\tremaining: 26s\n",
      "97:\tlearn: 0.6431813\ttotal: 2.82s\tremaining: 26s\n",
      "98:\tlearn: 0.6370369\ttotal: 2.85s\tremaining: 26s\n",
      "99:\tlearn: 0.6315597\ttotal: 2.88s\tremaining: 25.9s\n",
      "100:\tlearn: 0.6264990\ttotal: 2.91s\tremaining: 25.9s\n",
      "101:\tlearn: 0.6213076\ttotal: 2.94s\tremaining: 25.9s\n",
      "102:\tlearn: 0.6161134\ttotal: 2.97s\tremaining: 25.8s\n",
      "103:\tlearn: 0.6114613\ttotal: 3s\tremaining: 25.8s\n",
      "104:\tlearn: 0.6072199\ttotal: 3.02s\tremaining: 25.8s\n",
      "105:\tlearn: 0.6021727\ttotal: 3.05s\tremaining: 25.8s\n",
      "106:\tlearn: 0.5977055\ttotal: 3.08s\tremaining: 25.7s\n",
      "107:\tlearn: 0.5931029\ttotal: 3.1s\tremaining: 25.6s\n",
      "108:\tlearn: 0.5874476\ttotal: 3.13s\tremaining: 25.6s\n",
      "109:\tlearn: 0.5827814\ttotal: 3.16s\tremaining: 25.6s\n",
      "110:\tlearn: 0.5785586\ttotal: 3.18s\tremaining: 25.5s\n",
      "111:\tlearn: 0.5734701\ttotal: 3.21s\tremaining: 25.5s\n",
      "112:\tlearn: 0.5687203\ttotal: 3.24s\tremaining: 25.5s\n",
      "113:\tlearn: 0.5652197\ttotal: 3.27s\tremaining: 25.4s\n",
      "114:\tlearn: 0.5616315\ttotal: 3.3s\tremaining: 25.4s\n",
      "115:\tlearn: 0.5573788\ttotal: 3.32s\tremaining: 25.3s\n",
      "116:\tlearn: 0.5530258\ttotal: 3.35s\tremaining: 25.3s\n",
      "117:\tlearn: 0.5486323\ttotal: 3.38s\tremaining: 25.3s\n",
      "118:\tlearn: 0.5443623\ttotal: 3.4s\tremaining: 25.2s\n",
      "119:\tlearn: 0.5404515\ttotal: 3.43s\tremaining: 25.2s\n",
      "120:\tlearn: 0.5365894\ttotal: 3.46s\tremaining: 25.1s\n",
      "121:\tlearn: 0.5331003\ttotal: 3.49s\tremaining: 25.1s\n",
      "122:\tlearn: 0.5294247\ttotal: 3.51s\tremaining: 25.1s\n",
      "123:\tlearn: 0.5264964\ttotal: 3.54s\tremaining: 25s\n",
      "124:\tlearn: 0.5227427\ttotal: 3.57s\tremaining: 25s\n",
      "125:\tlearn: 0.5185395\ttotal: 3.6s\tremaining: 24.9s\n",
      "126:\tlearn: 0.5155073\ttotal: 3.62s\tremaining: 24.9s\n",
      "127:\tlearn: 0.5120300\ttotal: 3.65s\tremaining: 24.8s\n",
      "128:\tlearn: 0.5090438\ttotal: 3.67s\tremaining: 24.8s\n",
      "129:\tlearn: 0.5058488\ttotal: 3.7s\tremaining: 24.8s\n",
      "130:\tlearn: 0.5026157\ttotal: 3.73s\tremaining: 24.7s\n",
      "131:\tlearn: 0.4994406\ttotal: 3.75s\tremaining: 24.7s\n",
      "132:\tlearn: 0.4964477\ttotal: 3.78s\tremaining: 24.7s\n",
      "133:\tlearn: 0.4925848\ttotal: 3.81s\tremaining: 24.6s\n",
      "134:\tlearn: 0.4889196\ttotal: 3.84s\tremaining: 24.6s\n",
      "135:\tlearn: 0.4856174\ttotal: 3.86s\tremaining: 24.6s\n",
      "136:\tlearn: 0.4830549\ttotal: 3.89s\tremaining: 24.5s\n",
      "137:\tlearn: 0.4794613\ttotal: 3.92s\tremaining: 24.5s\n",
      "138:\tlearn: 0.4759971\ttotal: 3.95s\tremaining: 24.5s\n",
      "139:\tlearn: 0.4729353\ttotal: 3.98s\tremaining: 24.4s\n",
      "140:\tlearn: 0.4702979\ttotal: 4s\tremaining: 24.4s\n",
      "141:\tlearn: 0.4682771\ttotal: 4.03s\tremaining: 24.4s\n",
      "142:\tlearn: 0.4651442\ttotal: 4.06s\tremaining: 24.3s\n",
      "143:\tlearn: 0.4621117\ttotal: 4.09s\tremaining: 24.3s\n",
      "144:\tlearn: 0.4590961\ttotal: 4.12s\tremaining: 24.3s\n",
      "145:\tlearn: 0.4554232\ttotal: 4.14s\tremaining: 24.2s\n",
      "146:\tlearn: 0.4526623\ttotal: 4.17s\tremaining: 24.2s\n",
      "147:\tlearn: 0.4499530\ttotal: 4.2s\tremaining: 24.2s\n",
      "148:\tlearn: 0.4473381\ttotal: 4.23s\tremaining: 24.1s\n",
      "149:\tlearn: 0.4444488\ttotal: 4.25s\tremaining: 24.1s\n",
      "150:\tlearn: 0.4419166\ttotal: 4.28s\tremaining: 24.1s\n",
      "151:\tlearn: 0.4386842\ttotal: 4.31s\tremaining: 24s\n",
      "152:\tlearn: 0.4355439\ttotal: 4.33s\tremaining: 24s\n",
      "153:\tlearn: 0.4328384\ttotal: 4.36s\tremaining: 24s\n",
      "154:\tlearn: 0.4300533\ttotal: 4.39s\tremaining: 23.9s\n",
      "155:\tlearn: 0.4277749\ttotal: 4.41s\tremaining: 23.9s\n",
      "156:\tlearn: 0.4255147\ttotal: 4.44s\tremaining: 23.8s\n",
      "157:\tlearn: 0.4226019\ttotal: 4.47s\tremaining: 23.8s\n",
      "158:\tlearn: 0.4200130\ttotal: 4.49s\tremaining: 23.8s\n",
      "159:\tlearn: 0.4171134\ttotal: 4.52s\tremaining: 23.7s\n",
      "160:\tlearn: 0.4145011\ttotal: 4.55s\tremaining: 23.7s\n",
      "161:\tlearn: 0.4123492\ttotal: 4.58s\tremaining: 23.7s\n",
      "162:\tlearn: 0.4097094\ttotal: 4.6s\tremaining: 23.6s\n",
      "163:\tlearn: 0.4071135\ttotal: 4.63s\tremaining: 23.6s\n",
      "164:\tlearn: 0.4047155\ttotal: 4.65s\tremaining: 23.6s\n",
      "165:\tlearn: 0.4020718\ttotal: 4.68s\tremaining: 23.5s\n",
      "166:\tlearn: 0.3999654\ttotal: 4.71s\tremaining: 23.5s\n",
      "167:\tlearn: 0.3973039\ttotal: 4.73s\tremaining: 23.4s\n",
      "168:\tlearn: 0.3951090\ttotal: 4.76s\tremaining: 23.4s\n",
      "169:\tlearn: 0.3924981\ttotal: 4.79s\tremaining: 23.4s\n",
      "170:\tlearn: 0.3902383\ttotal: 4.82s\tremaining: 23.4s\n",
      "171:\tlearn: 0.3878441\ttotal: 4.84s\tremaining: 23.3s\n",
      "172:\tlearn: 0.3854314\ttotal: 4.87s\tremaining: 23.3s\n",
      "173:\tlearn: 0.3838798\ttotal: 4.89s\tremaining: 23.2s\n",
      "174:\tlearn: 0.3815872\ttotal: 4.92s\tremaining: 23.2s\n",
      "175:\tlearn: 0.3788676\ttotal: 4.95s\tremaining: 23.2s\n",
      "176:\tlearn: 0.3770368\ttotal: 4.97s\tremaining: 23.1s\n",
      "177:\tlearn: 0.3752032\ttotal: 5s\tremaining: 23.1s\n",
      "178:\tlearn: 0.3730446\ttotal: 5.02s\tremaining: 23s\n",
      "179:\tlearn: 0.3707594\ttotal: 5.05s\tremaining: 23s\n",
      "180:\tlearn: 0.3686212\ttotal: 5.07s\tremaining: 23s\n",
      "181:\tlearn: 0.3667521\ttotal: 5.1s\tremaining: 22.9s\n",
      "182:\tlearn: 0.3651158\ttotal: 5.12s\tremaining: 22.9s\n",
      "183:\tlearn: 0.3633140\ttotal: 5.15s\tremaining: 22.8s\n",
      "184:\tlearn: 0.3613344\ttotal: 5.17s\tremaining: 22.8s\n",
      "185:\tlearn: 0.3593722\ttotal: 5.2s\tremaining: 22.8s\n",
      "186:\tlearn: 0.3569387\ttotal: 5.23s\tremaining: 22.8s\n",
      "187:\tlearn: 0.3546512\ttotal: 5.26s\tremaining: 22.7s\n",
      "188:\tlearn: 0.3524851\ttotal: 5.29s\tremaining: 22.7s\n",
      "189:\tlearn: 0.3502929\ttotal: 5.31s\tremaining: 22.6s\n",
      "190:\tlearn: 0.3488231\ttotal: 5.33s\tremaining: 22.6s\n",
      "191:\tlearn: 0.3469263\ttotal: 5.36s\tremaining: 22.6s\n",
      "192:\tlearn: 0.3446111\ttotal: 5.39s\tremaining: 22.5s\n",
      "193:\tlearn: 0.3428426\ttotal: 5.42s\tremaining: 22.5s\n",
      "194:\tlearn: 0.3408549\ttotal: 5.44s\tremaining: 22.5s\n",
      "195:\tlearn: 0.3390377\ttotal: 5.47s\tremaining: 22.4s\n",
      "196:\tlearn: 0.3374475\ttotal: 5.49s\tremaining: 22.4s\n",
      "197:\tlearn: 0.3357643\ttotal: 5.52s\tremaining: 22.4s\n",
      "198:\tlearn: 0.3342150\ttotal: 5.54s\tremaining: 22.3s\n",
      "199:\tlearn: 0.3318278\ttotal: 5.57s\tremaining: 22.3s\n",
      "200:\tlearn: 0.3303154\ttotal: 5.59s\tremaining: 22.2s\n",
      "201:\tlearn: 0.3286834\ttotal: 5.62s\tremaining: 22.2s\n",
      "202:\tlearn: 0.3275277\ttotal: 5.65s\tremaining: 22.2s\n",
      "203:\tlearn: 0.3256418\ttotal: 5.67s\tremaining: 22.1s\n",
      "204:\tlearn: 0.3238090\ttotal: 5.7s\tremaining: 22.1s\n",
      "205:\tlearn: 0.3221489\ttotal: 5.73s\tremaining: 22.1s\n",
      "206:\tlearn: 0.3202936\ttotal: 5.75s\tremaining: 22s\n",
      "207:\tlearn: 0.3187748\ttotal: 5.78s\tremaining: 22s\n",
      "208:\tlearn: 0.3170847\ttotal: 5.81s\tremaining: 22s\n",
      "209:\tlearn: 0.3154243\ttotal: 5.84s\tremaining: 22s\n",
      "210:\tlearn: 0.3134059\ttotal: 5.86s\tremaining: 21.9s\n",
      "211:\tlearn: 0.3118780\ttotal: 5.89s\tremaining: 21.9s\n",
      "212:\tlearn: 0.3102606\ttotal: 5.91s\tremaining: 21.9s\n",
      "213:\tlearn: 0.3089670\ttotal: 5.94s\tremaining: 21.8s\n",
      "214:\tlearn: 0.3071627\ttotal: 5.97s\tremaining: 21.8s\n",
      "215:\tlearn: 0.3058108\ttotal: 5.99s\tremaining: 21.7s\n",
      "216:\tlearn: 0.3046215\ttotal: 6.01s\tremaining: 21.7s\n",
      "217:\tlearn: 0.3032810\ttotal: 6.04s\tremaining: 21.7s\n",
      "218:\tlearn: 0.3017845\ttotal: 6.07s\tremaining: 21.6s\n",
      "219:\tlearn: 0.3003173\ttotal: 6.09s\tremaining: 21.6s\n",
      "220:\tlearn: 0.2984799\ttotal: 6.12s\tremaining: 21.6s\n",
      "221:\tlearn: 0.2969037\ttotal: 6.14s\tremaining: 21.5s\n",
      "222:\tlearn: 0.2949375\ttotal: 6.17s\tremaining: 21.5s\n",
      "223:\tlearn: 0.2934123\ttotal: 6.2s\tremaining: 21.5s\n",
      "224:\tlearn: 0.2924148\ttotal: 6.22s\tremaining: 21.4s\n",
      "225:\tlearn: 0.2907623\ttotal: 6.25s\tremaining: 21.4s\n",
      "226:\tlearn: 0.2893280\ttotal: 6.28s\tremaining: 21.4s\n",
      "227:\tlearn: 0.2876261\ttotal: 6.31s\tremaining: 21.4s\n",
      "228:\tlearn: 0.2861832\ttotal: 6.33s\tremaining: 21.3s\n",
      "229:\tlearn: 0.2847669\ttotal: 6.36s\tremaining: 21.3s\n",
      "230:\tlearn: 0.2835033\ttotal: 6.39s\tremaining: 21.3s\n",
      "231:\tlearn: 0.2822825\ttotal: 6.41s\tremaining: 21.2s\n",
      "232:\tlearn: 0.2807925\ttotal: 6.44s\tremaining: 21.2s\n",
      "233:\tlearn: 0.2790064\ttotal: 6.47s\tremaining: 21.2s\n",
      "234:\tlearn: 0.2778643\ttotal: 6.49s\tremaining: 21.1s\n",
      "235:\tlearn: 0.2765744\ttotal: 6.52s\tremaining: 21.1s\n",
      "236:\tlearn: 0.2751687\ttotal: 6.54s\tremaining: 21.1s\n",
      "237:\tlearn: 0.2742038\ttotal: 6.57s\tremaining: 21s\n",
      "238:\tlearn: 0.2729987\ttotal: 6.59s\tremaining: 21s\n",
      "239:\tlearn: 0.2717301\ttotal: 6.62s\tremaining: 20.9s\n",
      "240:\tlearn: 0.2705713\ttotal: 6.64s\tremaining: 20.9s\n",
      "241:\tlearn: 0.2692751\ttotal: 6.67s\tremaining: 20.9s\n",
      "242:\tlearn: 0.2677843\ttotal: 6.69s\tremaining: 20.9s\n",
      "243:\tlearn: 0.2664710\ttotal: 6.72s\tremaining: 20.8s\n",
      "244:\tlearn: 0.2652381\ttotal: 6.75s\tremaining: 20.8s\n",
      "245:\tlearn: 0.2639369\ttotal: 6.77s\tremaining: 20.8s\n",
      "246:\tlearn: 0.2630010\ttotal: 6.8s\tremaining: 20.7s\n",
      "247:\tlearn: 0.2618420\ttotal: 6.82s\tremaining: 20.7s\n",
      "248:\tlearn: 0.2603598\ttotal: 6.85s\tremaining: 20.7s\n",
      "249:\tlearn: 0.2591058\ttotal: 6.88s\tremaining: 20.6s\n",
      "250:\tlearn: 0.2581430\ttotal: 6.9s\tremaining: 20.6s\n",
      "251:\tlearn: 0.2566744\ttotal: 6.93s\tremaining: 20.6s\n",
      "252:\tlearn: 0.2555156\ttotal: 6.96s\tremaining: 20.6s\n",
      "253:\tlearn: 0.2541262\ttotal: 6.99s\tremaining: 20.5s\n",
      "254:\tlearn: 0.2529987\ttotal: 7.02s\tremaining: 20.5s\n",
      "255:\tlearn: 0.2523237\ttotal: 7.04s\tremaining: 20.5s\n",
      "256:\tlearn: 0.2511529\ttotal: 7.07s\tremaining: 20.4s\n",
      "257:\tlearn: 0.2500357\ttotal: 7.09s\tremaining: 20.4s\n",
      "258:\tlearn: 0.2487578\ttotal: 7.12s\tremaining: 20.4s\n",
      "259:\tlearn: 0.2477261\ttotal: 7.14s\tremaining: 20.3s\n",
      "260:\tlearn: 0.2467740\ttotal: 7.17s\tremaining: 20.3s\n",
      "261:\tlearn: 0.2460827\ttotal: 7.2s\tremaining: 20.3s\n",
      "262:\tlearn: 0.2453042\ttotal: 7.22s\tremaining: 20.2s\n",
      "263:\tlearn: 0.2441700\ttotal: 7.25s\tremaining: 20.2s\n",
      "264:\tlearn: 0.2432343\ttotal: 7.28s\tremaining: 20.2s\n",
      "265:\tlearn: 0.2422352\ttotal: 7.3s\tremaining: 20.1s\n",
      "266:\tlearn: 0.2411820\ttotal: 7.32s\tremaining: 20.1s\n",
      "267:\tlearn: 0.2400258\ttotal: 7.35s\tremaining: 20.1s\n",
      "268:\tlearn: 0.2388947\ttotal: 7.37s\tremaining: 20s\n",
      "269:\tlearn: 0.2377607\ttotal: 7.4s\tremaining: 20s\n",
      "270:\tlearn: 0.2367723\ttotal: 7.42s\tremaining: 20s\n",
      "271:\tlearn: 0.2359037\ttotal: 7.45s\tremaining: 19.9s\n",
      "272:\tlearn: 0.2348766\ttotal: 7.47s\tremaining: 19.9s\n",
      "273:\tlearn: 0.2337435\ttotal: 7.5s\tremaining: 19.9s\n",
      "274:\tlearn: 0.2325252\ttotal: 7.53s\tremaining: 19.9s\n",
      "275:\tlearn: 0.2316170\ttotal: 7.55s\tremaining: 19.8s\n",
      "276:\tlearn: 0.2305695\ttotal: 7.58s\tremaining: 19.8s\n",
      "277:\tlearn: 0.2295408\ttotal: 7.61s\tremaining: 19.8s\n",
      "278:\tlearn: 0.2285366\ttotal: 7.63s\tremaining: 19.7s\n",
      "279:\tlearn: 0.2274667\ttotal: 7.66s\tremaining: 19.7s\n",
      "280:\tlearn: 0.2263754\ttotal: 7.69s\tremaining: 19.7s\n",
      "281:\tlearn: 0.2252917\ttotal: 7.71s\tremaining: 19.6s\n",
      "282:\tlearn: 0.2243255\ttotal: 7.74s\tremaining: 19.6s\n",
      "283:\tlearn: 0.2235358\ttotal: 7.76s\tremaining: 19.6s\n",
      "284:\tlearn: 0.2226895\ttotal: 7.79s\tremaining: 19.5s\n",
      "285:\tlearn: 0.2217758\ttotal: 7.81s\tremaining: 19.5s\n",
      "286:\tlearn: 0.2208736\ttotal: 7.84s\tremaining: 19.5s\n",
      "287:\tlearn: 0.2200080\ttotal: 7.86s\tremaining: 19.4s\n",
      "288:\tlearn: 0.2193020\ttotal: 7.89s\tremaining: 19.4s\n",
      "289:\tlearn: 0.2182547\ttotal: 7.91s\tremaining: 19.4s\n",
      "290:\tlearn: 0.2174782\ttotal: 7.93s\tremaining: 19.3s\n",
      "291:\tlearn: 0.2167371\ttotal: 7.96s\tremaining: 19.3s\n",
      "292:\tlearn: 0.2158960\ttotal: 7.99s\tremaining: 19.3s\n",
      "293:\tlearn: 0.2148197\ttotal: 8.01s\tremaining: 19.2s\n",
      "294:\tlearn: 0.2143057\ttotal: 8.04s\tremaining: 19.2s\n",
      "295:\tlearn: 0.2135759\ttotal: 8.06s\tremaining: 19.2s\n",
      "296:\tlearn: 0.2128114\ttotal: 8.09s\tremaining: 19.1s\n",
      "297:\tlearn: 0.2119919\ttotal: 8.11s\tremaining: 19.1s\n",
      "298:\tlearn: 0.2109310\ttotal: 8.14s\tremaining: 19.1s\n",
      "299:\tlearn: 0.2101547\ttotal: 8.16s\tremaining: 19.1s\n",
      "300:\tlearn: 0.2092743\ttotal: 8.19s\tremaining: 19s\n",
      "301:\tlearn: 0.2083818\ttotal: 8.22s\tremaining: 19s\n",
      "302:\tlearn: 0.2076938\ttotal: 8.24s\tremaining: 19s\n",
      "303:\tlearn: 0.2069999\ttotal: 8.27s\tremaining: 18.9s\n",
      "304:\tlearn: 0.2062402\ttotal: 8.3s\tremaining: 18.9s\n",
      "305:\tlearn: 0.2054808\ttotal: 8.32s\tremaining: 18.9s\n",
      "306:\tlearn: 0.2048660\ttotal: 8.35s\tremaining: 18.8s\n",
      "307:\tlearn: 0.2039135\ttotal: 8.37s\tremaining: 18.8s\n",
      "308:\tlearn: 0.2032232\ttotal: 8.4s\tremaining: 18.8s\n",
      "309:\tlearn: 0.2025708\ttotal: 8.42s\tremaining: 18.7s\n",
      "310:\tlearn: 0.2017368\ttotal: 8.45s\tremaining: 18.7s\n",
      "311:\tlearn: 0.2008398\ttotal: 8.48s\tremaining: 18.7s\n",
      "312:\tlearn: 0.2003674\ttotal: 8.5s\tremaining: 18.7s\n",
      "313:\tlearn: 0.1995895\ttotal: 8.52s\tremaining: 18.6s\n",
      "314:\tlearn: 0.1989963\ttotal: 8.55s\tremaining: 18.6s\n",
      "315:\tlearn: 0.1982923\ttotal: 8.57s\tremaining: 18.6s\n",
      "316:\tlearn: 0.1977446\ttotal: 8.6s\tremaining: 18.5s\n",
      "317:\tlearn: 0.1967791\ttotal: 8.63s\tremaining: 18.5s\n",
      "318:\tlearn: 0.1959274\ttotal: 8.65s\tremaining: 18.5s\n",
      "319:\tlearn: 0.1951750\ttotal: 8.68s\tremaining: 18.4s\n",
      "320:\tlearn: 0.1943745\ttotal: 8.71s\tremaining: 18.4s\n",
      "321:\tlearn: 0.1935096\ttotal: 8.73s\tremaining: 18.4s\n",
      "322:\tlearn: 0.1929726\ttotal: 8.75s\tremaining: 18.3s\n",
      "323:\tlearn: 0.1924210\ttotal: 8.78s\tremaining: 18.3s\n",
      "324:\tlearn: 0.1917449\ttotal: 8.8s\tremaining: 18.3s\n",
      "325:\tlearn: 0.1908461\ttotal: 8.83s\tremaining: 18.2s\n",
      "326:\tlearn: 0.1901005\ttotal: 8.85s\tremaining: 18.2s\n",
      "327:\tlearn: 0.1894933\ttotal: 8.88s\tremaining: 18.2s\n",
      "328:\tlearn: 0.1886416\ttotal: 8.91s\tremaining: 18.2s\n",
      "329:\tlearn: 0.1877575\ttotal: 8.93s\tremaining: 18.1s\n",
      "330:\tlearn: 0.1870188\ttotal: 8.96s\tremaining: 18.1s\n",
      "331:\tlearn: 0.1863117\ttotal: 8.98s\tremaining: 18.1s\n",
      "332:\tlearn: 0.1857587\ttotal: 9.01s\tremaining: 18.1s\n",
      "333:\tlearn: 0.1852431\ttotal: 9.04s\tremaining: 18s\n",
      "334:\tlearn: 0.1845409\ttotal: 9.06s\tremaining: 18s\n",
      "335:\tlearn: 0.1840309\ttotal: 9.09s\tremaining: 18s\n",
      "336:\tlearn: 0.1835117\ttotal: 9.11s\tremaining: 17.9s\n",
      "337:\tlearn: 0.1828981\ttotal: 9.14s\tremaining: 17.9s\n",
      "338:\tlearn: 0.1822043\ttotal: 9.16s\tremaining: 17.9s\n",
      "339:\tlearn: 0.1817078\ttotal: 9.19s\tremaining: 17.8s\n",
      "340:\tlearn: 0.1809939\ttotal: 9.21s\tremaining: 17.8s\n",
      "341:\tlearn: 0.1805198\ttotal: 9.24s\tremaining: 17.8s\n",
      "342:\tlearn: 0.1796758\ttotal: 9.27s\tremaining: 17.7s\n",
      "343:\tlearn: 0.1787701\ttotal: 9.29s\tremaining: 17.7s\n",
      "344:\tlearn: 0.1781882\ttotal: 9.32s\tremaining: 17.7s\n",
      "345:\tlearn: 0.1775902\ttotal: 9.35s\tremaining: 17.7s\n",
      "346:\tlearn: 0.1770176\ttotal: 9.37s\tremaining: 17.6s\n",
      "347:\tlearn: 0.1765146\ttotal: 9.4s\tremaining: 17.6s\n",
      "348:\tlearn: 0.1758162\ttotal: 9.42s\tremaining: 17.6s\n",
      "349:\tlearn: 0.1753973\ttotal: 9.45s\tremaining: 17.5s\n",
      "350:\tlearn: 0.1747878\ttotal: 9.47s\tremaining: 17.5s\n",
      "351:\tlearn: 0.1741448\ttotal: 9.5s\tremaining: 17.5s\n",
      "352:\tlearn: 0.1735747\ttotal: 9.52s\tremaining: 17.5s\n",
      "353:\tlearn: 0.1728650\ttotal: 9.55s\tremaining: 17.4s\n",
      "354:\tlearn: 0.1721247\ttotal: 9.58s\tremaining: 17.4s\n",
      "355:\tlearn: 0.1715332\ttotal: 9.6s\tremaining: 17.4s\n",
      "356:\tlearn: 0.1708981\ttotal: 9.63s\tremaining: 17.3s\n",
      "357:\tlearn: 0.1703752\ttotal: 9.65s\tremaining: 17.3s\n",
      "358:\tlearn: 0.1697287\ttotal: 9.68s\tremaining: 17.3s\n",
      "359:\tlearn: 0.1691755\ttotal: 9.7s\tremaining: 17.2s\n",
      "360:\tlearn: 0.1685623\ttotal: 9.73s\tremaining: 17.2s\n",
      "361:\tlearn: 0.1679944\ttotal: 9.75s\tremaining: 17.2s\n",
      "362:\tlearn: 0.1675562\ttotal: 9.78s\tremaining: 17.2s\n",
      "363:\tlearn: 0.1670092\ttotal: 9.8s\tremaining: 17.1s\n",
      "364:\tlearn: 0.1666030\ttotal: 9.83s\tremaining: 17.1s\n",
      "365:\tlearn: 0.1661277\ttotal: 9.85s\tremaining: 17.1s\n",
      "366:\tlearn: 0.1656089\ttotal: 9.88s\tremaining: 17s\n",
      "367:\tlearn: 0.1649973\ttotal: 9.9s\tremaining: 17s\n",
      "368:\tlearn: 0.1646537\ttotal: 9.93s\tremaining: 17s\n",
      "369:\tlearn: 0.1640472\ttotal: 9.95s\tremaining: 16.9s\n",
      "370:\tlearn: 0.1635896\ttotal: 9.97s\tremaining: 16.9s\n",
      "371:\tlearn: 0.1629696\ttotal: 10s\tremaining: 16.9s\n",
      "372:\tlearn: 0.1622950\ttotal: 10s\tremaining: 16.9s\n",
      "373:\tlearn: 0.1616850\ttotal: 10.1s\tremaining: 16.8s\n",
      "374:\tlearn: 0.1611372\ttotal: 10.1s\tremaining: 16.8s\n",
      "375:\tlearn: 0.1606303\ttotal: 10.1s\tremaining: 16.8s\n",
      "376:\tlearn: 0.1601890\ttotal: 10.1s\tremaining: 16.7s\n",
      "377:\tlearn: 0.1594980\ttotal: 10.2s\tremaining: 16.7s\n",
      "378:\tlearn: 0.1588802\ttotal: 10.2s\tremaining: 16.7s\n",
      "379:\tlearn: 0.1583434\ttotal: 10.2s\tremaining: 16.7s\n",
      "380:\tlearn: 0.1579441\ttotal: 10.2s\tremaining: 16.6s\n",
      "381:\tlearn: 0.1576382\ttotal: 10.3s\tremaining: 16.6s\n",
      "382:\tlearn: 0.1570896\ttotal: 10.3s\tremaining: 16.6s\n",
      "383:\tlearn: 0.1566048\ttotal: 10.3s\tremaining: 16.5s\n",
      "384:\tlearn: 0.1560795\ttotal: 10.3s\tremaining: 16.5s\n",
      "385:\tlearn: 0.1555131\ttotal: 10.4s\tremaining: 16.5s\n",
      "386:\tlearn: 0.1550146\ttotal: 10.4s\tremaining: 16.5s\n",
      "387:\tlearn: 0.1545022\ttotal: 10.4s\tremaining: 16.4s\n",
      "388:\tlearn: 0.1540939\ttotal: 10.4s\tremaining: 16.4s\n",
      "389:\tlearn: 0.1535958\ttotal: 10.5s\tremaining: 16.4s\n",
      "390:\tlearn: 0.1530542\ttotal: 10.5s\tremaining: 16.3s\n",
      "391:\tlearn: 0.1525704\ttotal: 10.5s\tremaining: 16.3s\n",
      "392:\tlearn: 0.1520940\ttotal: 10.5s\tremaining: 16.3s\n",
      "393:\tlearn: 0.1517340\ttotal: 10.6s\tremaining: 16.3s\n",
      "394:\tlearn: 0.1511671\ttotal: 10.6s\tremaining: 16.2s\n",
      "395:\tlearn: 0.1507824\ttotal: 10.6s\tremaining: 16.2s\n",
      "396:\tlearn: 0.1503448\ttotal: 10.6s\tremaining: 16.2s\n",
      "397:\tlearn: 0.1499794\ttotal: 10.7s\tremaining: 16.1s\n",
      "398:\tlearn: 0.1495404\ttotal: 10.7s\tremaining: 16.1s\n",
      "399:\tlearn: 0.1490751\ttotal: 10.7s\tremaining: 16.1s\n",
      "400:\tlearn: 0.1486973\ttotal: 10.7s\tremaining: 16.1s\n",
      "401:\tlearn: 0.1482597\ttotal: 10.8s\tremaining: 16s\n",
      "402:\tlearn: 0.1477377\ttotal: 10.8s\tremaining: 16s\n",
      "403:\tlearn: 0.1472145\ttotal: 10.8s\tremaining: 16s\n",
      "404:\tlearn: 0.1468931\ttotal: 10.8s\tremaining: 15.9s\n",
      "405:\tlearn: 0.1466566\ttotal: 10.9s\tremaining: 15.9s\n",
      "406:\tlearn: 0.1461848\ttotal: 10.9s\tremaining: 15.9s\n",
      "407:\tlearn: 0.1458342\ttotal: 10.9s\tremaining: 15.9s\n",
      "408:\tlearn: 0.1454269\ttotal: 11s\tremaining: 15.8s\n",
      "409:\tlearn: 0.1450816\ttotal: 11s\tremaining: 15.8s\n",
      "410:\tlearn: 0.1447148\ttotal: 11s\tremaining: 15.8s\n",
      "411:\tlearn: 0.1444104\ttotal: 11s\tremaining: 15.7s\n",
      "412:\tlearn: 0.1439485\ttotal: 11.1s\tremaining: 15.7s\n",
      "413:\tlearn: 0.1434817\ttotal: 11.1s\tremaining: 15.7s\n",
      "414:\tlearn: 0.1429874\ttotal: 11.1s\tremaining: 15.7s\n",
      "415:\tlearn: 0.1425060\ttotal: 11.1s\tremaining: 15.6s\n",
      "416:\tlearn: 0.1421854\ttotal: 11.2s\tremaining: 15.6s\n",
      "417:\tlearn: 0.1417072\ttotal: 11.2s\tremaining: 15.6s\n",
      "418:\tlearn: 0.1413847\ttotal: 11.2s\tremaining: 15.5s\n",
      "419:\tlearn: 0.1409560\ttotal: 11.2s\tremaining: 15.5s\n",
      "420:\tlearn: 0.1406691\ttotal: 11.3s\tremaining: 15.5s\n",
      "421:\tlearn: 0.1403181\ttotal: 11.3s\tremaining: 15.4s\n",
      "422:\tlearn: 0.1400063\ttotal: 11.3s\tremaining: 15.4s\n",
      "423:\tlearn: 0.1396115\ttotal: 11.3s\tremaining: 15.4s\n",
      "424:\tlearn: 0.1391088\ttotal: 11.4s\tremaining: 15.4s\n",
      "425:\tlearn: 0.1385814\ttotal: 11.4s\tremaining: 15.3s\n",
      "426:\tlearn: 0.1383416\ttotal: 11.4s\tremaining: 15.3s\n",
      "427:\tlearn: 0.1379732\ttotal: 11.4s\tremaining: 15.3s\n",
      "428:\tlearn: 0.1376884\ttotal: 11.5s\tremaining: 15.2s\n",
      "429:\tlearn: 0.1375108\ttotal: 11.5s\tremaining: 15.2s\n",
      "430:\tlearn: 0.1371515\ttotal: 11.5s\tremaining: 15.2s\n",
      "431:\tlearn: 0.1368962\ttotal: 11.5s\tremaining: 15.2s\n",
      "432:\tlearn: 0.1365775\ttotal: 11.6s\tremaining: 15.1s\n",
      "433:\tlearn: 0.1361371\ttotal: 11.6s\tremaining: 15.1s\n",
      "434:\tlearn: 0.1358018\ttotal: 11.6s\tremaining: 15.1s\n",
      "435:\tlearn: 0.1353072\ttotal: 11.6s\tremaining: 15s\n",
      "436:\tlearn: 0.1350473\ttotal: 11.7s\tremaining: 15s\n",
      "437:\tlearn: 0.1346135\ttotal: 11.7s\tremaining: 15s\n",
      "438:\tlearn: 0.1342373\ttotal: 11.7s\tremaining: 15s\n",
      "439:\tlearn: 0.1337454\ttotal: 11.7s\tremaining: 14.9s\n",
      "440:\tlearn: 0.1334778\ttotal: 11.8s\tremaining: 14.9s\n",
      "441:\tlearn: 0.1330461\ttotal: 11.8s\tremaining: 14.9s\n",
      "442:\tlearn: 0.1327593\ttotal: 11.8s\tremaining: 14.9s\n",
      "443:\tlearn: 0.1323501\ttotal: 11.8s\tremaining: 14.8s\n",
      "444:\tlearn: 0.1319592\ttotal: 11.9s\tremaining: 14.8s\n",
      "445:\tlearn: 0.1315764\ttotal: 11.9s\tremaining: 14.8s\n",
      "446:\tlearn: 0.1312927\ttotal: 11.9s\tremaining: 14.7s\n",
      "447:\tlearn: 0.1308685\ttotal: 11.9s\tremaining: 14.7s\n",
      "448:\tlearn: 0.1305790\ttotal: 12s\tremaining: 14.7s\n",
      "449:\tlearn: 0.1301656\ttotal: 12s\tremaining: 14.7s\n",
      "450:\tlearn: 0.1298604\ttotal: 12s\tremaining: 14.6s\n",
      "451:\tlearn: 0.1295589\ttotal: 12s\tremaining: 14.6s\n",
      "452:\tlearn: 0.1292043\ttotal: 12.1s\tremaining: 14.6s\n",
      "453:\tlearn: 0.1289644\ttotal: 12.1s\tremaining: 14.5s\n",
      "454:\tlearn: 0.1286274\ttotal: 12.1s\tremaining: 14.5s\n",
      "455:\tlearn: 0.1281941\ttotal: 12.1s\tremaining: 14.5s\n",
      "456:\tlearn: 0.1279472\ttotal: 12.2s\tremaining: 14.4s\n",
      "457:\tlearn: 0.1275186\ttotal: 12.2s\tremaining: 14.4s\n",
      "458:\tlearn: 0.1271018\ttotal: 12.2s\tremaining: 14.4s\n",
      "459:\tlearn: 0.1268697\ttotal: 12.2s\tremaining: 14.4s\n",
      "460:\tlearn: 0.1265722\ttotal: 12.3s\tremaining: 14.3s\n",
      "461:\tlearn: 0.1262560\ttotal: 12.3s\tremaining: 14.3s\n",
      "462:\tlearn: 0.1260832\ttotal: 12.3s\tremaining: 14.3s\n",
      "463:\tlearn: 0.1257734\ttotal: 12.3s\tremaining: 14.2s\n",
      "464:\tlearn: 0.1253755\ttotal: 12.4s\tremaining: 14.2s\n",
      "465:\tlearn: 0.1251233\ttotal: 12.4s\tremaining: 14.2s\n",
      "466:\tlearn: 0.1247526\ttotal: 12.4s\tremaining: 14.2s\n",
      "467:\tlearn: 0.1245068\ttotal: 12.4s\tremaining: 14.1s\n",
      "468:\tlearn: 0.1242637\ttotal: 12.5s\tremaining: 14.1s\n",
      "469:\tlearn: 0.1239824\ttotal: 12.5s\tremaining: 14.1s\n",
      "470:\tlearn: 0.1238285\ttotal: 12.5s\tremaining: 14s\n",
      "471:\tlearn: 0.1235614\ttotal: 12.5s\tremaining: 14s\n",
      "472:\tlearn: 0.1232433\ttotal: 12.6s\tremaining: 14s\n",
      "473:\tlearn: 0.1228792\ttotal: 12.6s\tremaining: 14s\n",
      "474:\tlearn: 0.1226278\ttotal: 12.6s\tremaining: 13.9s\n",
      "475:\tlearn: 0.1222959\ttotal: 12.6s\tremaining: 13.9s\n",
      "476:\tlearn: 0.1219688\ttotal: 12.6s\tremaining: 13.9s\n",
      "477:\tlearn: 0.1216527\ttotal: 12.7s\tremaining: 13.8s\n",
      "478:\tlearn: 0.1213686\ttotal: 12.7s\tremaining: 13.8s\n",
      "479:\tlearn: 0.1211485\ttotal: 12.7s\tremaining: 13.8s\n",
      "480:\tlearn: 0.1207674\ttotal: 12.7s\tremaining: 13.8s\n",
      "481:\tlearn: 0.1205457\ttotal: 12.8s\tremaining: 13.7s\n",
      "482:\tlearn: 0.1202055\ttotal: 12.8s\tremaining: 13.7s\n",
      "483:\tlearn: 0.1199143\ttotal: 12.8s\tremaining: 13.7s\n",
      "484:\tlearn: 0.1195636\ttotal: 12.8s\tremaining: 13.6s\n",
      "485:\tlearn: 0.1193061\ttotal: 12.9s\tremaining: 13.6s\n",
      "486:\tlearn: 0.1189699\ttotal: 12.9s\tremaining: 13.6s\n",
      "487:\tlearn: 0.1186476\ttotal: 12.9s\tremaining: 13.6s\n",
      "488:\tlearn: 0.1182523\ttotal: 13s\tremaining: 13.5s\n",
      "489:\tlearn: 0.1178896\ttotal: 13s\tremaining: 13.5s\n",
      "490:\tlearn: 0.1175187\ttotal: 13s\tremaining: 13.5s\n",
      "491:\tlearn: 0.1173036\ttotal: 13s\tremaining: 13.4s\n",
      "492:\tlearn: 0.1170381\ttotal: 13.1s\tremaining: 13.4s\n",
      "493:\tlearn: 0.1168539\ttotal: 13.1s\tremaining: 13.4s\n",
      "494:\tlearn: 0.1165269\ttotal: 13.1s\tremaining: 13.4s\n",
      "495:\tlearn: 0.1163089\ttotal: 13.1s\tremaining: 13.3s\n",
      "496:\tlearn: 0.1160205\ttotal: 13.2s\tremaining: 13.3s\n",
      "497:\tlearn: 0.1157083\ttotal: 13.2s\tremaining: 13.3s\n",
      "498:\tlearn: 0.1154058\ttotal: 13.2s\tremaining: 13.3s\n",
      "499:\tlearn: 0.1151163\ttotal: 13.2s\tremaining: 13.2s\n",
      "500:\tlearn: 0.1149406\ttotal: 13.2s\tremaining: 13.2s\n",
      "501:\tlearn: 0.1147084\ttotal: 13.3s\tremaining: 13.2s\n",
      "502:\tlearn: 0.1144224\ttotal: 13.3s\tremaining: 13.1s\n",
      "503:\tlearn: 0.1141703\ttotal: 13.3s\tremaining: 13.1s\n",
      "504:\tlearn: 0.1139406\ttotal: 13.3s\tremaining: 13.1s\n",
      "505:\tlearn: 0.1136287\ttotal: 13.4s\tremaining: 13.1s\n",
      "506:\tlearn: 0.1133791\ttotal: 13.4s\tremaining: 13s\n",
      "507:\tlearn: 0.1131942\ttotal: 13.4s\tremaining: 13s\n",
      "508:\tlearn: 0.1129524\ttotal: 13.4s\tremaining: 13s\n",
      "509:\tlearn: 0.1127922\ttotal: 13.5s\tremaining: 12.9s\n",
      "510:\tlearn: 0.1125378\ttotal: 13.5s\tremaining: 12.9s\n",
      "511:\tlearn: 0.1122694\ttotal: 13.5s\tremaining: 12.9s\n",
      "512:\tlearn: 0.1121338\ttotal: 13.5s\tremaining: 12.9s\n",
      "513:\tlearn: 0.1119041\ttotal: 13.6s\tremaining: 12.8s\n",
      "514:\tlearn: 0.1116126\ttotal: 13.6s\tremaining: 12.8s\n",
      "515:\tlearn: 0.1113518\ttotal: 13.6s\tremaining: 12.8s\n",
      "516:\tlearn: 0.1111100\ttotal: 13.6s\tremaining: 12.7s\n",
      "517:\tlearn: 0.1108756\ttotal: 13.7s\tremaining: 12.7s\n",
      "518:\tlearn: 0.1106757\ttotal: 13.7s\tremaining: 12.7s\n",
      "519:\tlearn: 0.1104060\ttotal: 13.7s\tremaining: 12.7s\n",
      "520:\tlearn: 0.1101952\ttotal: 13.7s\tremaining: 12.6s\n",
      "521:\tlearn: 0.1100098\ttotal: 13.8s\tremaining: 12.6s\n",
      "522:\tlearn: 0.1097501\ttotal: 13.8s\tremaining: 12.6s\n",
      "523:\tlearn: 0.1094518\ttotal: 13.8s\tremaining: 12.5s\n",
      "524:\tlearn: 0.1093335\ttotal: 13.8s\tremaining: 12.5s\n",
      "525:\tlearn: 0.1091275\ttotal: 13.9s\tremaining: 12.5s\n",
      "526:\tlearn: 0.1089198\ttotal: 13.9s\tremaining: 12.5s\n",
      "527:\tlearn: 0.1085914\ttotal: 13.9s\tremaining: 12.4s\n",
      "528:\tlearn: 0.1083678\ttotal: 13.9s\tremaining: 12.4s\n",
      "529:\tlearn: 0.1082069\ttotal: 14s\tremaining: 12.4s\n",
      "530:\tlearn: 0.1080946\ttotal: 14s\tremaining: 12.3s\n",
      "531:\tlearn: 0.1078725\ttotal: 14s\tremaining: 12.3s\n",
      "532:\tlearn: 0.1076972\ttotal: 14s\tremaining: 12.3s\n",
      "533:\tlearn: 0.1074854\ttotal: 14.1s\tremaining: 12.3s\n",
      "534:\tlearn: 0.1073377\ttotal: 14.1s\tremaining: 12.2s\n",
      "535:\tlearn: 0.1071858\ttotal: 14.1s\tremaining: 12.2s\n",
      "536:\tlearn: 0.1069187\ttotal: 14.1s\tremaining: 12.2s\n",
      "537:\tlearn: 0.1066744\ttotal: 14.1s\tremaining: 12.2s\n",
      "538:\tlearn: 0.1065288\ttotal: 14.2s\tremaining: 12.1s\n",
      "539:\tlearn: 0.1063255\ttotal: 14.2s\tremaining: 12.1s\n",
      "540:\tlearn: 0.1060385\ttotal: 14.2s\tremaining: 12.1s\n",
      "541:\tlearn: 0.1057614\ttotal: 14.3s\tremaining: 12s\n",
      "542:\tlearn: 0.1055635\ttotal: 14.3s\tremaining: 12s\n",
      "543:\tlearn: 0.1054280\ttotal: 14.3s\tremaining: 12s\n",
      "544:\tlearn: 0.1051791\ttotal: 14.3s\tremaining: 12s\n",
      "545:\tlearn: 0.1049908\ttotal: 14.3s\tremaining: 11.9s\n",
      "546:\tlearn: 0.1047482\ttotal: 14.4s\tremaining: 11.9s\n",
      "547:\tlearn: 0.1044757\ttotal: 14.4s\tremaining: 11.9s\n",
      "548:\tlearn: 0.1042096\ttotal: 14.4s\tremaining: 11.8s\n",
      "549:\tlearn: 0.1040058\ttotal: 14.4s\tremaining: 11.8s\n",
      "550:\tlearn: 0.1038367\ttotal: 14.5s\tremaining: 11.8s\n",
      "551:\tlearn: 0.1035590\ttotal: 14.5s\tremaining: 11.8s\n",
      "552:\tlearn: 0.1033057\ttotal: 14.5s\tremaining: 11.7s\n",
      "553:\tlearn: 0.1031123\ttotal: 14.5s\tremaining: 11.7s\n",
      "554:\tlearn: 0.1030508\ttotal: 14.6s\tremaining: 11.7s\n",
      "555:\tlearn: 0.1028982\ttotal: 14.6s\tremaining: 11.6s\n",
      "556:\tlearn: 0.1026802\ttotal: 14.6s\tremaining: 11.6s\n",
      "557:\tlearn: 0.1025489\ttotal: 14.6s\tremaining: 11.6s\n",
      "558:\tlearn: 0.1023759\ttotal: 14.7s\tremaining: 11.6s\n",
      "559:\tlearn: 0.1020685\ttotal: 14.7s\tremaining: 11.5s\n",
      "560:\tlearn: 0.1018873\ttotal: 14.7s\tremaining: 11.5s\n",
      "561:\tlearn: 0.1016671\ttotal: 14.7s\tremaining: 11.5s\n",
      "562:\tlearn: 0.1014845\ttotal: 14.8s\tremaining: 11.5s\n",
      "563:\tlearn: 0.1013255\ttotal: 14.8s\tremaining: 11.4s\n",
      "564:\tlearn: 0.1012323\ttotal: 14.8s\tremaining: 11.4s\n",
      "565:\tlearn: 0.1010683\ttotal: 14.8s\tremaining: 11.4s\n",
      "566:\tlearn: 0.1009286\ttotal: 14.8s\tremaining: 11.3s\n",
      "567:\tlearn: 0.1007354\ttotal: 14.9s\tremaining: 11.3s\n",
      "568:\tlearn: 0.1004543\ttotal: 14.9s\tremaining: 11.3s\n",
      "569:\tlearn: 0.1002146\ttotal: 14.9s\tremaining: 11.3s\n",
      "570:\tlearn: 0.1000421\ttotal: 14.9s\tremaining: 11.2s\n",
      "571:\tlearn: 0.0998057\ttotal: 15s\tremaining: 11.2s\n",
      "572:\tlearn: 0.0996694\ttotal: 15s\tremaining: 11.2s\n",
      "573:\tlearn: 0.0994322\ttotal: 15s\tremaining: 11.1s\n",
      "574:\tlearn: 0.0992932\ttotal: 15s\tremaining: 11.1s\n",
      "575:\tlearn: 0.0991077\ttotal: 15.1s\tremaining: 11.1s\n",
      "576:\tlearn: 0.0989408\ttotal: 15.1s\tremaining: 11.1s\n",
      "577:\tlearn: 0.0987945\ttotal: 15.1s\tremaining: 11s\n",
      "578:\tlearn: 0.0985674\ttotal: 15.1s\tremaining: 11s\n",
      "579:\tlearn: 0.0983696\ttotal: 15.2s\tremaining: 11s\n",
      "580:\tlearn: 0.0982076\ttotal: 15.2s\tremaining: 10.9s\n",
      "581:\tlearn: 0.0980194\ttotal: 15.2s\tremaining: 10.9s\n",
      "582:\tlearn: 0.0978521\ttotal: 15.2s\tremaining: 10.9s\n",
      "583:\tlearn: 0.0977559\ttotal: 15.3s\tremaining: 10.9s\n",
      "584:\tlearn: 0.0975566\ttotal: 15.3s\tremaining: 10.8s\n",
      "585:\tlearn: 0.0974143\ttotal: 15.3s\tremaining: 10.8s\n",
      "586:\tlearn: 0.0972766\ttotal: 15.3s\tremaining: 10.8s\n",
      "587:\tlearn: 0.0971137\ttotal: 15.4s\tremaining: 10.8s\n",
      "588:\tlearn: 0.0969945\ttotal: 15.4s\tremaining: 10.7s\n",
      "589:\tlearn: 0.0968973\ttotal: 15.4s\tremaining: 10.7s\n",
      "590:\tlearn: 0.0966988\ttotal: 15.4s\tremaining: 10.7s\n",
      "591:\tlearn: 0.0964748\ttotal: 15.4s\tremaining: 10.6s\n",
      "592:\tlearn: 0.0962346\ttotal: 15.5s\tremaining: 10.6s\n",
      "593:\tlearn: 0.0961239\ttotal: 15.5s\tremaining: 10.6s\n",
      "594:\tlearn: 0.0960025\ttotal: 15.5s\tremaining: 10.6s\n",
      "595:\tlearn: 0.0957569\ttotal: 15.5s\tremaining: 10.5s\n",
      "596:\tlearn: 0.0955641\ttotal: 15.6s\tremaining: 10.5s\n",
      "597:\tlearn: 0.0953686\ttotal: 15.6s\tremaining: 10.5s\n",
      "598:\tlearn: 0.0952709\ttotal: 15.6s\tremaining: 10.5s\n",
      "599:\tlearn: 0.0950812\ttotal: 15.6s\tremaining: 10.4s\n",
      "600:\tlearn: 0.0948898\ttotal: 15.7s\tremaining: 10.4s\n",
      "601:\tlearn: 0.0947866\ttotal: 15.7s\tremaining: 10.4s\n",
      "602:\tlearn: 0.0945908\ttotal: 15.7s\tremaining: 10.3s\n",
      "603:\tlearn: 0.0944098\ttotal: 15.7s\tremaining: 10.3s\n",
      "604:\tlearn: 0.0942760\ttotal: 15.8s\tremaining: 10.3s\n",
      "605:\tlearn: 0.0941540\ttotal: 15.8s\tremaining: 10.3s\n",
      "606:\tlearn: 0.0940002\ttotal: 15.8s\tremaining: 10.2s\n",
      "607:\tlearn: 0.0938753\ttotal: 15.8s\tremaining: 10.2s\n",
      "608:\tlearn: 0.0936527\ttotal: 15.9s\tremaining: 10.2s\n",
      "609:\tlearn: 0.0934431\ttotal: 15.9s\tremaining: 10.2s\n",
      "610:\tlearn: 0.0933006\ttotal: 15.9s\tremaining: 10.1s\n",
      "611:\tlearn: 0.0931810\ttotal: 15.9s\tremaining: 10.1s\n",
      "612:\tlearn: 0.0930662\ttotal: 16s\tremaining: 10.1s\n",
      "613:\tlearn: 0.0928735\ttotal: 16s\tremaining: 10s\n",
      "614:\tlearn: 0.0927505\ttotal: 16s\tremaining: 10s\n",
      "615:\tlearn: 0.0926332\ttotal: 16s\tremaining: 9.99s\n",
      "616:\tlearn: 0.0924120\ttotal: 16.1s\tremaining: 9.97s\n",
      "617:\tlearn: 0.0922600\ttotal: 16.1s\tremaining: 9.94s\n",
      "618:\tlearn: 0.0920876\ttotal: 16.1s\tremaining: 9.91s\n",
      "619:\tlearn: 0.0918549\ttotal: 16.1s\tremaining: 9.89s\n",
      "620:\tlearn: 0.0917582\ttotal: 16.2s\tremaining: 9.86s\n",
      "621:\tlearn: 0.0916672\ttotal: 16.2s\tremaining: 9.83s\n",
      "622:\tlearn: 0.0915398\ttotal: 16.2s\tremaining: 9.81s\n",
      "623:\tlearn: 0.0914083\ttotal: 16.2s\tremaining: 9.78s\n",
      "624:\tlearn: 0.0912533\ttotal: 16.3s\tremaining: 9.75s\n",
      "625:\tlearn: 0.0911160\ttotal: 16.3s\tremaining: 9.72s\n",
      "626:\tlearn: 0.0910439\ttotal: 16.3s\tremaining: 9.69s\n",
      "627:\tlearn: 0.0908765\ttotal: 16.3s\tremaining: 9.67s\n",
      "628:\tlearn: 0.0906781\ttotal: 16.3s\tremaining: 9.64s\n",
      "629:\tlearn: 0.0905231\ttotal: 16.4s\tremaining: 9.61s\n",
      "630:\tlearn: 0.0903589\ttotal: 16.4s\tremaining: 9.59s\n",
      "631:\tlearn: 0.0901950\ttotal: 16.4s\tremaining: 9.56s\n",
      "632:\tlearn: 0.0901005\ttotal: 16.4s\tremaining: 9.53s\n",
      "633:\tlearn: 0.0899944\ttotal: 16.5s\tremaining: 9.5s\n",
      "634:\tlearn: 0.0898929\ttotal: 16.5s\tremaining: 9.47s\n",
      "635:\tlearn: 0.0897399\ttotal: 16.5s\tremaining: 9.45s\n",
      "636:\tlearn: 0.0896460\ttotal: 16.5s\tremaining: 9.42s\n",
      "637:\tlearn: 0.0894534\ttotal: 16.6s\tremaining: 9.39s\n",
      "638:\tlearn: 0.0892440\ttotal: 16.6s\tremaining: 9.37s\n",
      "639:\tlearn: 0.0890632\ttotal: 16.6s\tremaining: 9.34s\n",
      "640:\tlearn: 0.0889867\ttotal: 16.6s\tremaining: 9.31s\n",
      "641:\tlearn: 0.0887701\ttotal: 16.6s\tremaining: 9.28s\n",
      "642:\tlearn: 0.0886281\ttotal: 16.7s\tremaining: 9.26s\n",
      "643:\tlearn: 0.0885031\ttotal: 16.7s\tremaining: 9.23s\n",
      "644:\tlearn: 0.0883185\ttotal: 16.7s\tremaining: 9.2s\n",
      "645:\tlearn: 0.0881780\ttotal: 16.7s\tremaining: 9.18s\n",
      "646:\tlearn: 0.0880886\ttotal: 16.8s\tremaining: 9.15s\n",
      "647:\tlearn: 0.0879718\ttotal: 16.8s\tremaining: 9.12s\n",
      "648:\tlearn: 0.0878373\ttotal: 16.8s\tremaining: 9.1s\n",
      "649:\tlearn: 0.0876661\ttotal: 16.9s\tremaining: 9.08s\n",
      "650:\tlearn: 0.0875151\ttotal: 16.9s\tremaining: 9.05s\n",
      "651:\tlearn: 0.0873307\ttotal: 16.9s\tremaining: 9.03s\n",
      "652:\tlearn: 0.0871792\ttotal: 16.9s\tremaining: 9s\n",
      "653:\tlearn: 0.0870507\ttotal: 17s\tremaining: 8.97s\n",
      "654:\tlearn: 0.0869669\ttotal: 17s\tremaining: 8.95s\n",
      "655:\tlearn: 0.0868500\ttotal: 17s\tremaining: 8.92s\n",
      "656:\tlearn: 0.0867114\ttotal: 17s\tremaining: 8.89s\n",
      "657:\tlearn: 0.0866567\ttotal: 17.1s\tremaining: 8.87s\n",
      "658:\tlearn: 0.0865297\ttotal: 17.1s\tremaining: 8.84s\n",
      "659:\tlearn: 0.0864603\ttotal: 17.1s\tremaining: 8.81s\n",
      "660:\tlearn: 0.0863221\ttotal: 17.1s\tremaining: 8.79s\n",
      "661:\tlearn: 0.0862173\ttotal: 17.2s\tremaining: 8.76s\n",
      "662:\tlearn: 0.0861216\ttotal: 17.2s\tremaining: 8.73s\n",
      "663:\tlearn: 0.0860610\ttotal: 17.2s\tremaining: 8.7s\n",
      "664:\tlearn: 0.0859091\ttotal: 17.2s\tremaining: 8.68s\n",
      "665:\tlearn: 0.0858294\ttotal: 17.2s\tremaining: 8.65s\n",
      "666:\tlearn: 0.0856458\ttotal: 17.3s\tremaining: 8.62s\n",
      "667:\tlearn: 0.0855166\ttotal: 17.3s\tremaining: 8.6s\n",
      "668:\tlearn: 0.0853538\ttotal: 17.3s\tremaining: 8.57s\n",
      "669:\tlearn: 0.0852646\ttotal: 17.3s\tremaining: 8.54s\n",
      "670:\tlearn: 0.0851761\ttotal: 17.4s\tremaining: 8.51s\n",
      "671:\tlearn: 0.0849751\ttotal: 17.4s\tremaining: 8.49s\n",
      "672:\tlearn: 0.0849021\ttotal: 17.4s\tremaining: 8.46s\n",
      "673:\tlearn: 0.0847666\ttotal: 17.4s\tremaining: 8.43s\n",
      "674:\tlearn: 0.0846846\ttotal: 17.5s\tremaining: 8.4s\n",
      "675:\tlearn: 0.0846124\ttotal: 17.5s\tremaining: 8.38s\n",
      "676:\tlearn: 0.0845239\ttotal: 17.5s\tremaining: 8.35s\n",
      "677:\tlearn: 0.0844145\ttotal: 17.5s\tremaining: 8.32s\n",
      "678:\tlearn: 0.0843297\ttotal: 17.5s\tremaining: 8.29s\n",
      "679:\tlearn: 0.0842638\ttotal: 17.6s\tremaining: 8.27s\n",
      "680:\tlearn: 0.0841189\ttotal: 17.6s\tremaining: 8.24s\n",
      "681:\tlearn: 0.0840506\ttotal: 17.6s\tremaining: 8.21s\n",
      "682:\tlearn: 0.0839058\ttotal: 17.6s\tremaining: 8.19s\n",
      "683:\tlearn: 0.0838065\ttotal: 17.7s\tremaining: 8.16s\n",
      "684:\tlearn: 0.0837677\ttotal: 17.7s\tremaining: 8.13s\n",
      "685:\tlearn: 0.0836049\ttotal: 17.7s\tremaining: 8.11s\n",
      "686:\tlearn: 0.0835294\ttotal: 17.8s\tremaining: 8.09s\n",
      "687:\tlearn: 0.0834010\ttotal: 17.8s\tremaining: 8.06s\n",
      "688:\tlearn: 0.0833389\ttotal: 17.8s\tremaining: 8.04s\n",
      "689:\tlearn: 0.0832698\ttotal: 17.8s\tremaining: 8.01s\n",
      "690:\tlearn: 0.0831196\ttotal: 17.8s\tremaining: 7.98s\n",
      "691:\tlearn: 0.0830065\ttotal: 17.9s\tremaining: 7.95s\n",
      "692:\tlearn: 0.0828481\ttotal: 17.9s\tremaining: 7.93s\n",
      "693:\tlearn: 0.0827444\ttotal: 17.9s\tremaining: 7.9s\n",
      "694:\tlearn: 0.0826447\ttotal: 17.9s\tremaining: 7.88s\n",
      "695:\tlearn: 0.0825332\ttotal: 18s\tremaining: 7.85s\n",
      "696:\tlearn: 0.0824511\ttotal: 18s\tremaining: 7.82s\n",
      "697:\tlearn: 0.0822892\ttotal: 18s\tremaining: 7.79s\n",
      "698:\tlearn: 0.0821993\ttotal: 18s\tremaining: 7.77s\n",
      "699:\tlearn: 0.0820977\ttotal: 18.1s\tremaining: 7.74s\n",
      "700:\tlearn: 0.0820021\ttotal: 18.1s\tremaining: 7.71s\n",
      "701:\tlearn: 0.0819070\ttotal: 18.1s\tremaining: 7.69s\n",
      "702:\tlearn: 0.0818001\ttotal: 18.1s\tremaining: 7.66s\n",
      "703:\tlearn: 0.0816930\ttotal: 18.2s\tremaining: 7.64s\n",
      "704:\tlearn: 0.0815459\ttotal: 18.2s\tremaining: 7.61s\n",
      "705:\tlearn: 0.0814305\ttotal: 18.2s\tremaining: 7.58s\n",
      "706:\tlearn: 0.0813116\ttotal: 18.2s\tremaining: 7.56s\n",
      "707:\tlearn: 0.0812370\ttotal: 18.3s\tremaining: 7.54s\n",
      "708:\tlearn: 0.0810787\ttotal: 18.3s\tremaining: 7.51s\n",
      "709:\tlearn: 0.0809354\ttotal: 18.3s\tremaining: 7.49s\n",
      "710:\tlearn: 0.0808698\ttotal: 18.4s\tremaining: 7.46s\n",
      "711:\tlearn: 0.0807292\ttotal: 18.4s\tremaining: 7.43s\n",
      "712:\tlearn: 0.0806160\ttotal: 18.4s\tremaining: 7.41s\n",
      "713:\tlearn: 0.0805903\ttotal: 18.4s\tremaining: 7.38s\n",
      "714:\tlearn: 0.0804655\ttotal: 18.5s\tremaining: 7.36s\n",
      "715:\tlearn: 0.0802982\ttotal: 18.5s\tremaining: 7.33s\n",
      "716:\tlearn: 0.0801408\ttotal: 18.5s\tremaining: 7.3s\n",
      "717:\tlearn: 0.0800583\ttotal: 18.5s\tremaining: 7.28s\n",
      "718:\tlearn: 0.0799800\ttotal: 18.5s\tremaining: 7.25s\n",
      "719:\tlearn: 0.0798780\ttotal: 18.6s\tremaining: 7.22s\n",
      "720:\tlearn: 0.0797356\ttotal: 18.6s\tremaining: 7.2s\n",
      "721:\tlearn: 0.0796276\ttotal: 18.6s\tremaining: 7.17s\n",
      "722:\tlearn: 0.0795477\ttotal: 18.6s\tremaining: 7.14s\n",
      "723:\tlearn: 0.0793590\ttotal: 18.7s\tremaining: 7.12s\n",
      "724:\tlearn: 0.0792287\ttotal: 18.7s\tremaining: 7.09s\n",
      "725:\tlearn: 0.0790901\ttotal: 18.7s\tremaining: 7.07s\n",
      "726:\tlearn: 0.0789701\ttotal: 18.8s\tremaining: 7.04s\n",
      "727:\tlearn: 0.0788734\ttotal: 18.8s\tremaining: 7.01s\n",
      "728:\tlearn: 0.0787271\ttotal: 18.8s\tremaining: 6.99s\n",
      "729:\tlearn: 0.0786177\ttotal: 18.8s\tremaining: 6.96s\n",
      "730:\tlearn: 0.0785811\ttotal: 18.9s\tremaining: 6.94s\n",
      "731:\tlearn: 0.0784627\ttotal: 18.9s\tremaining: 6.91s\n",
      "732:\tlearn: 0.0783633\ttotal: 18.9s\tremaining: 6.88s\n",
      "733:\tlearn: 0.0782440\ttotal: 18.9s\tremaining: 6.86s\n",
      "734:\tlearn: 0.0781008\ttotal: 19s\tremaining: 6.83s\n",
      "735:\tlearn: 0.0780304\ttotal: 19s\tremaining: 6.81s\n",
      "736:\tlearn: 0.0779065\ttotal: 19s\tremaining: 6.78s\n",
      "737:\tlearn: 0.0777834\ttotal: 19s\tremaining: 6.75s\n",
      "738:\tlearn: 0.0776842\ttotal: 19.1s\tremaining: 6.73s\n",
      "739:\tlearn: 0.0776072\ttotal: 19.1s\tremaining: 6.7s\n",
      "740:\tlearn: 0.0775363\ttotal: 19.1s\tremaining: 6.68s\n",
      "741:\tlearn: 0.0774678\ttotal: 19.1s\tremaining: 6.65s\n",
      "742:\tlearn: 0.0773252\ttotal: 19.1s\tremaining: 6.62s\n",
      "743:\tlearn: 0.0772238\ttotal: 19.2s\tremaining: 6.6s\n",
      "744:\tlearn: 0.0771247\ttotal: 19.2s\tremaining: 6.57s\n",
      "745:\tlearn: 0.0770852\ttotal: 19.2s\tremaining: 6.54s\n",
      "746:\tlearn: 0.0769581\ttotal: 19.2s\tremaining: 6.52s\n",
      "747:\tlearn: 0.0768615\ttotal: 19.3s\tremaining: 6.49s\n",
      "748:\tlearn: 0.0767428\ttotal: 19.3s\tremaining: 6.46s\n",
      "749:\tlearn: 0.0766727\ttotal: 19.3s\tremaining: 6.44s\n",
      "750:\tlearn: 0.0765625\ttotal: 19.3s\tremaining: 6.41s\n",
      "751:\tlearn: 0.0765086\ttotal: 19.4s\tremaining: 6.39s\n",
      "752:\tlearn: 0.0764477\ttotal: 19.4s\tremaining: 6.36s\n",
      "753:\tlearn: 0.0764020\ttotal: 19.4s\tremaining: 6.33s\n",
      "754:\tlearn: 0.0763052\ttotal: 19.4s\tremaining: 6.31s\n",
      "755:\tlearn: 0.0762779\ttotal: 19.5s\tremaining: 6.28s\n",
      "756:\tlearn: 0.0762351\ttotal: 19.5s\tremaining: 6.25s\n",
      "757:\tlearn: 0.0761608\ttotal: 19.5s\tremaining: 6.23s\n",
      "758:\tlearn: 0.0761132\ttotal: 19.5s\tremaining: 6.2s\n",
      "759:\tlearn: 0.0760314\ttotal: 19.6s\tremaining: 6.17s\n",
      "760:\tlearn: 0.0759271\ttotal: 19.6s\tremaining: 6.15s\n",
      "761:\tlearn: 0.0758452\ttotal: 19.6s\tremaining: 6.12s\n",
      "762:\tlearn: 0.0757697\ttotal: 19.6s\tremaining: 6.09s\n",
      "763:\tlearn: 0.0756706\ttotal: 19.6s\tremaining: 6.07s\n",
      "764:\tlearn: 0.0755517\ttotal: 19.7s\tremaining: 6.04s\n",
      "765:\tlearn: 0.0754155\ttotal: 19.7s\tremaining: 6.02s\n",
      "766:\tlearn: 0.0752988\ttotal: 19.7s\tremaining: 5.99s\n",
      "767:\tlearn: 0.0752120\ttotal: 19.7s\tremaining: 5.96s\n",
      "768:\tlearn: 0.0750788\ttotal: 19.8s\tremaining: 5.94s\n",
      "769:\tlearn: 0.0749706\ttotal: 19.8s\tremaining: 5.91s\n",
      "770:\tlearn: 0.0749175\ttotal: 19.8s\tremaining: 5.89s\n",
      "771:\tlearn: 0.0748281\ttotal: 19.8s\tremaining: 5.86s\n",
      "772:\tlearn: 0.0747364\ttotal: 19.9s\tremaining: 5.83s\n",
      "773:\tlearn: 0.0746370\ttotal: 19.9s\tremaining: 5.81s\n",
      "774:\tlearn: 0.0745467\ttotal: 19.9s\tremaining: 5.78s\n",
      "775:\tlearn: 0.0744982\ttotal: 19.9s\tremaining: 5.76s\n",
      "776:\tlearn: 0.0744001\ttotal: 20s\tremaining: 5.73s\n",
      "777:\tlearn: 0.0743202\ttotal: 20s\tremaining: 5.7s\n",
      "778:\tlearn: 0.0742235\ttotal: 20s\tremaining: 5.68s\n",
      "779:\tlearn: 0.0740916\ttotal: 20s\tremaining: 5.65s\n",
      "780:\tlearn: 0.0740175\ttotal: 20.1s\tremaining: 5.63s\n",
      "781:\tlearn: 0.0739657\ttotal: 20.1s\tremaining: 5.6s\n",
      "782:\tlearn: 0.0738349\ttotal: 20.1s\tremaining: 5.57s\n",
      "783:\tlearn: 0.0737861\ttotal: 20.1s\tremaining: 5.55s\n",
      "784:\tlearn: 0.0736468\ttotal: 20.2s\tremaining: 5.52s\n",
      "785:\tlearn: 0.0735616\ttotal: 20.2s\tremaining: 5.5s\n",
      "786:\tlearn: 0.0734978\ttotal: 20.2s\tremaining: 5.47s\n",
      "787:\tlearn: 0.0734408\ttotal: 20.2s\tremaining: 5.44s\n",
      "788:\tlearn: 0.0733351\ttotal: 20.3s\tremaining: 5.42s\n",
      "789:\tlearn: 0.0732338\ttotal: 20.3s\tremaining: 5.39s\n",
      "790:\tlearn: 0.0731447\ttotal: 20.3s\tremaining: 5.37s\n",
      "791:\tlearn: 0.0730718\ttotal: 20.3s\tremaining: 5.34s\n",
      "792:\tlearn: 0.0730544\ttotal: 20.4s\tremaining: 5.31s\n",
      "793:\tlearn: 0.0730253\ttotal: 20.4s\tremaining: 5.29s\n",
      "794:\tlearn: 0.0729131\ttotal: 20.4s\tremaining: 5.26s\n",
      "795:\tlearn: 0.0728475\ttotal: 20.4s\tremaining: 5.24s\n",
      "796:\tlearn: 0.0727271\ttotal: 20.5s\tremaining: 5.21s\n",
      "797:\tlearn: 0.0726895\ttotal: 20.5s\tremaining: 5.18s\n",
      "798:\tlearn: 0.0726202\ttotal: 20.5s\tremaining: 5.16s\n",
      "799:\tlearn: 0.0725599\ttotal: 20.5s\tremaining: 5.13s\n",
      "800:\tlearn: 0.0724763\ttotal: 20.6s\tremaining: 5.11s\n",
      "801:\tlearn: 0.0723502\ttotal: 20.6s\tremaining: 5.08s\n",
      "802:\tlearn: 0.0722320\ttotal: 20.6s\tremaining: 5.05s\n",
      "803:\tlearn: 0.0721837\ttotal: 20.6s\tremaining: 5.03s\n",
      "804:\tlearn: 0.0721023\ttotal: 20.6s\tremaining: 5s\n",
      "805:\tlearn: 0.0720378\ttotal: 20.7s\tremaining: 4.97s\n",
      "806:\tlearn: 0.0719316\ttotal: 20.7s\tremaining: 4.95s\n",
      "807:\tlearn: 0.0718632\ttotal: 20.7s\tremaining: 4.92s\n",
      "808:\tlearn: 0.0717666\ttotal: 20.7s\tremaining: 4.9s\n",
      "809:\tlearn: 0.0717197\ttotal: 20.8s\tremaining: 4.87s\n",
      "810:\tlearn: 0.0716909\ttotal: 20.8s\tremaining: 4.85s\n",
      "811:\tlearn: 0.0716525\ttotal: 20.8s\tremaining: 4.82s\n",
      "812:\tlearn: 0.0715868\ttotal: 20.8s\tremaining: 4.79s\n",
      "813:\tlearn: 0.0715350\ttotal: 20.9s\tremaining: 4.77s\n",
      "814:\tlearn: 0.0714471\ttotal: 20.9s\tremaining: 4.74s\n",
      "815:\tlearn: 0.0713807\ttotal: 20.9s\tremaining: 4.72s\n",
      "816:\tlearn: 0.0712941\ttotal: 20.9s\tremaining: 4.69s\n",
      "817:\tlearn: 0.0712397\ttotal: 21s\tremaining: 4.67s\n",
      "818:\tlearn: 0.0711069\ttotal: 21s\tremaining: 4.64s\n",
      "819:\tlearn: 0.0710397\ttotal: 21s\tremaining: 4.61s\n",
      "820:\tlearn: 0.0709477\ttotal: 21.1s\tremaining: 4.59s\n",
      "821:\tlearn: 0.0708668\ttotal: 21.1s\tremaining: 4.56s\n",
      "822:\tlearn: 0.0708290\ttotal: 21.1s\tremaining: 4.54s\n",
      "823:\tlearn: 0.0707954\ttotal: 21.1s\tremaining: 4.51s\n",
      "824:\tlearn: 0.0707591\ttotal: 21.1s\tremaining: 4.49s\n",
      "825:\tlearn: 0.0706893\ttotal: 21.2s\tremaining: 4.46s\n",
      "826:\tlearn: 0.0706331\ttotal: 21.2s\tremaining: 4.43s\n",
      "827:\tlearn: 0.0705277\ttotal: 21.2s\tremaining: 4.41s\n",
      "828:\tlearn: 0.0704391\ttotal: 21.3s\tremaining: 4.39s\n",
      "829:\tlearn: 0.0703534\ttotal: 21.3s\tremaining: 4.36s\n",
      "830:\tlearn: 0.0703070\ttotal: 21.3s\tremaining: 4.33s\n",
      "831:\tlearn: 0.0702758\ttotal: 21.3s\tremaining: 4.31s\n",
      "832:\tlearn: 0.0702009\ttotal: 21.4s\tremaining: 4.28s\n",
      "833:\tlearn: 0.0701365\ttotal: 21.4s\tremaining: 4.26s\n",
      "834:\tlearn: 0.0700332\ttotal: 21.4s\tremaining: 4.23s\n",
      "835:\tlearn: 0.0699987\ttotal: 21.4s\tremaining: 4.21s\n",
      "836:\tlearn: 0.0698666\ttotal: 21.5s\tremaining: 4.18s\n",
      "837:\tlearn: 0.0697981\ttotal: 21.5s\tremaining: 4.15s\n",
      "838:\tlearn: 0.0697571\ttotal: 21.5s\tremaining: 4.13s\n",
      "839:\tlearn: 0.0696744\ttotal: 21.5s\tremaining: 4.1s\n",
      "840:\tlearn: 0.0696271\ttotal: 21.6s\tremaining: 4.08s\n",
      "841:\tlearn: 0.0695691\ttotal: 21.6s\tremaining: 4.05s\n",
      "842:\tlearn: 0.0694699\ttotal: 21.6s\tremaining: 4.02s\n",
      "843:\tlearn: 0.0693844\ttotal: 21.6s\tremaining: 4s\n",
      "844:\tlearn: 0.0693058\ttotal: 21.7s\tremaining: 3.97s\n",
      "845:\tlearn: 0.0692467\ttotal: 21.7s\tremaining: 3.95s\n",
      "846:\tlearn: 0.0691704\ttotal: 21.7s\tremaining: 3.92s\n",
      "847:\tlearn: 0.0691159\ttotal: 21.7s\tremaining: 3.89s\n",
      "848:\tlearn: 0.0690179\ttotal: 21.7s\tremaining: 3.87s\n",
      "849:\tlearn: 0.0689315\ttotal: 21.8s\tremaining: 3.84s\n",
      "850:\tlearn: 0.0688910\ttotal: 21.8s\tremaining: 3.82s\n",
      "851:\tlearn: 0.0688539\ttotal: 21.8s\tremaining: 3.79s\n",
      "852:\tlearn: 0.0688191\ttotal: 21.8s\tremaining: 3.76s\n",
      "853:\tlearn: 0.0687091\ttotal: 21.9s\tremaining: 3.74s\n",
      "854:\tlearn: 0.0686675\ttotal: 21.9s\tremaining: 3.71s\n",
      "855:\tlearn: 0.0685958\ttotal: 21.9s\tremaining: 3.69s\n",
      "856:\tlearn: 0.0684925\ttotal: 21.9s\tremaining: 3.66s\n",
      "857:\tlearn: 0.0684510\ttotal: 22s\tremaining: 3.64s\n",
      "858:\tlearn: 0.0683477\ttotal: 22s\tremaining: 3.61s\n",
      "859:\tlearn: 0.0682488\ttotal: 22s\tremaining: 3.58s\n",
      "860:\tlearn: 0.0681763\ttotal: 22s\tremaining: 3.56s\n",
      "861:\tlearn: 0.0681273\ttotal: 22.1s\tremaining: 3.53s\n",
      "862:\tlearn: 0.0680772\ttotal: 22.1s\tremaining: 3.51s\n",
      "863:\tlearn: 0.0680014\ttotal: 22.1s\tremaining: 3.48s\n",
      "864:\tlearn: 0.0679677\ttotal: 22.1s\tremaining: 3.46s\n",
      "865:\tlearn: 0.0678943\ttotal: 22.2s\tremaining: 3.43s\n",
      "866:\tlearn: 0.0678294\ttotal: 22.2s\tremaining: 3.4s\n",
      "867:\tlearn: 0.0677632\ttotal: 22.2s\tremaining: 3.38s\n",
      "868:\tlearn: 0.0676742\ttotal: 22.2s\tremaining: 3.35s\n",
      "869:\tlearn: 0.0675925\ttotal: 22.3s\tremaining: 3.33s\n",
      "870:\tlearn: 0.0675238\ttotal: 22.3s\tremaining: 3.3s\n",
      "871:\tlearn: 0.0674835\ttotal: 22.3s\tremaining: 3.28s\n",
      "872:\tlearn: 0.0674031\ttotal: 22.3s\tremaining: 3.25s\n",
      "873:\tlearn: 0.0673502\ttotal: 22.4s\tremaining: 3.23s\n",
      "874:\tlearn: 0.0672740\ttotal: 22.4s\tremaining: 3.2s\n",
      "875:\tlearn: 0.0671895\ttotal: 22.4s\tremaining: 3.17s\n",
      "876:\tlearn: 0.0671265\ttotal: 22.5s\tremaining: 3.15s\n",
      "877:\tlearn: 0.0670630\ttotal: 22.5s\tremaining: 3.12s\n",
      "878:\tlearn: 0.0669879\ttotal: 22.5s\tremaining: 3.1s\n",
      "879:\tlearn: 0.0669069\ttotal: 22.5s\tremaining: 3.07s\n",
      "880:\tlearn: 0.0668425\ttotal: 22.6s\tremaining: 3.05s\n",
      "881:\tlearn: 0.0667704\ttotal: 22.6s\tremaining: 3.02s\n",
      "882:\tlearn: 0.0667031\ttotal: 22.6s\tremaining: 3s\n",
      "883:\tlearn: 0.0666170\ttotal: 22.6s\tremaining: 2.97s\n",
      "884:\tlearn: 0.0665527\ttotal: 22.7s\tremaining: 2.94s\n",
      "885:\tlearn: 0.0664773\ttotal: 22.7s\tremaining: 2.92s\n",
      "886:\tlearn: 0.0664487\ttotal: 22.7s\tremaining: 2.9s\n",
      "887:\tlearn: 0.0663905\ttotal: 22.8s\tremaining: 2.87s\n",
      "888:\tlearn: 0.0663290\ttotal: 22.8s\tremaining: 2.84s\n",
      "889:\tlearn: 0.0662838\ttotal: 22.8s\tremaining: 2.82s\n",
      "890:\tlearn: 0.0662329\ttotal: 22.8s\tremaining: 2.79s\n",
      "891:\tlearn: 0.0662142\ttotal: 22.9s\tremaining: 2.77s\n",
      "892:\tlearn: 0.0661759\ttotal: 22.9s\tremaining: 2.74s\n",
      "893:\tlearn: 0.0661442\ttotal: 22.9s\tremaining: 2.72s\n",
      "894:\tlearn: 0.0660951\ttotal: 22.9s\tremaining: 2.69s\n",
      "895:\tlearn: 0.0660332\ttotal: 23s\tremaining: 2.67s\n",
      "896:\tlearn: 0.0660020\ttotal: 23s\tremaining: 2.64s\n",
      "897:\tlearn: 0.0659428\ttotal: 23s\tremaining: 2.61s\n",
      "898:\tlearn: 0.0658741\ttotal: 23s\tremaining: 2.59s\n",
      "899:\tlearn: 0.0657990\ttotal: 23.1s\tremaining: 2.56s\n",
      "900:\tlearn: 0.0657481\ttotal: 23.1s\tremaining: 2.54s\n",
      "901:\tlearn: 0.0657074\ttotal: 23.1s\tremaining: 2.51s\n",
      "902:\tlearn: 0.0656456\ttotal: 23.1s\tremaining: 2.48s\n",
      "903:\tlearn: 0.0655422\ttotal: 23.2s\tremaining: 2.46s\n",
      "904:\tlearn: 0.0654988\ttotal: 23.2s\tremaining: 2.43s\n",
      "905:\tlearn: 0.0654501\ttotal: 23.2s\tremaining: 2.41s\n",
      "906:\tlearn: 0.0653599\ttotal: 23.2s\tremaining: 2.38s\n",
      "907:\tlearn: 0.0652977\ttotal: 23.3s\tremaining: 2.36s\n",
      "908:\tlearn: 0.0652573\ttotal: 23.3s\tremaining: 2.33s\n",
      "909:\tlearn: 0.0651747\ttotal: 23.3s\tremaining: 2.31s\n",
      "910:\tlearn: 0.0651253\ttotal: 23.4s\tremaining: 2.28s\n",
      "911:\tlearn: 0.0650686\ttotal: 23.4s\tremaining: 2.26s\n",
      "912:\tlearn: 0.0650257\ttotal: 23.4s\tremaining: 2.23s\n",
      "913:\tlearn: 0.0649519\ttotal: 23.5s\tremaining: 2.21s\n",
      "914:\tlearn: 0.0648716\ttotal: 23.5s\tremaining: 2.18s\n",
      "915:\tlearn: 0.0647775\ttotal: 23.5s\tremaining: 2.16s\n",
      "916:\tlearn: 0.0647241\ttotal: 23.5s\tremaining: 2.13s\n",
      "917:\tlearn: 0.0646851\ttotal: 23.6s\tremaining: 2.1s\n",
      "918:\tlearn: 0.0646652\ttotal: 23.6s\tremaining: 2.08s\n",
      "919:\tlearn: 0.0645990\ttotal: 23.6s\tremaining: 2.05s\n",
      "920:\tlearn: 0.0644924\ttotal: 23.6s\tremaining: 2.03s\n",
      "921:\tlearn: 0.0644462\ttotal: 23.7s\tremaining: 2s\n",
      "922:\tlearn: 0.0644236\ttotal: 23.7s\tremaining: 1.98s\n",
      "923:\tlearn: 0.0643918\ttotal: 23.7s\tremaining: 1.95s\n",
      "924:\tlearn: 0.0643542\ttotal: 23.7s\tremaining: 1.92s\n",
      "925:\tlearn: 0.0642683\ttotal: 23.8s\tremaining: 1.9s\n",
      "926:\tlearn: 0.0642065\ttotal: 23.8s\tremaining: 1.87s\n",
      "927:\tlearn: 0.0641369\ttotal: 23.8s\tremaining: 1.85s\n",
      "928:\tlearn: 0.0640979\ttotal: 23.8s\tremaining: 1.82s\n",
      "929:\tlearn: 0.0640206\ttotal: 23.9s\tremaining: 1.8s\n",
      "930:\tlearn: 0.0639759\ttotal: 23.9s\tremaining: 1.77s\n",
      "931:\tlearn: 0.0639228\ttotal: 23.9s\tremaining: 1.74s\n",
      "932:\tlearn: 0.0638828\ttotal: 23.9s\tremaining: 1.72s\n",
      "933:\tlearn: 0.0638390\ttotal: 24s\tremaining: 1.69s\n",
      "934:\tlearn: 0.0637511\ttotal: 24s\tremaining: 1.67s\n",
      "935:\tlearn: 0.0637080\ttotal: 24s\tremaining: 1.64s\n",
      "936:\tlearn: 0.0636251\ttotal: 24s\tremaining: 1.61s\n",
      "937:\tlearn: 0.0635859\ttotal: 24.1s\tremaining: 1.59s\n",
      "938:\tlearn: 0.0635392\ttotal: 24.1s\tremaining: 1.56s\n",
      "939:\tlearn: 0.0634936\ttotal: 24.1s\tremaining: 1.54s\n",
      "940:\tlearn: 0.0634691\ttotal: 24.1s\tremaining: 1.51s\n",
      "941:\tlearn: 0.0634252\ttotal: 24.2s\tremaining: 1.49s\n",
      "942:\tlearn: 0.0633339\ttotal: 24.2s\tremaining: 1.46s\n",
      "943:\tlearn: 0.0632846\ttotal: 24.2s\tremaining: 1.44s\n",
      "944:\tlearn: 0.0631754\ttotal: 24.2s\tremaining: 1.41s\n",
      "945:\tlearn: 0.0631185\ttotal: 24.3s\tremaining: 1.38s\n",
      "946:\tlearn: 0.0630532\ttotal: 24.3s\tremaining: 1.36s\n",
      "947:\tlearn: 0.0629987\ttotal: 24.3s\tremaining: 1.33s\n",
      "948:\tlearn: 0.0629604\ttotal: 24.3s\tremaining: 1.31s\n",
      "949:\tlearn: 0.0628971\ttotal: 24.4s\tremaining: 1.28s\n",
      "950:\tlearn: 0.0628261\ttotal: 24.4s\tremaining: 1.26s\n",
      "951:\tlearn: 0.0627496\ttotal: 24.4s\tremaining: 1.23s\n",
      "952:\tlearn: 0.0627167\ttotal: 24.4s\tremaining: 1.2s\n",
      "953:\tlearn: 0.0626660\ttotal: 24.5s\tremaining: 1.18s\n",
      "954:\tlearn: 0.0626414\ttotal: 24.5s\tremaining: 1.15s\n",
      "955:\tlearn: 0.0626131\ttotal: 24.5s\tremaining: 1.13s\n",
      "956:\tlearn: 0.0625574\ttotal: 24.5s\tremaining: 1.1s\n",
      "957:\tlearn: 0.0625038\ttotal: 24.6s\tremaining: 1.08s\n",
      "958:\tlearn: 0.0624795\ttotal: 24.6s\tremaining: 1.05s\n",
      "959:\tlearn: 0.0624370\ttotal: 24.6s\tremaining: 1.02s\n",
      "960:\tlearn: 0.0623914\ttotal: 24.6s\tremaining: 999ms\n",
      "961:\tlearn: 0.0623751\ttotal: 24.6s\tremaining: 974ms\n",
      "962:\tlearn: 0.0623173\ttotal: 24.7s\tremaining: 948ms\n",
      "963:\tlearn: 0.0622771\ttotal: 24.7s\tremaining: 922ms\n",
      "964:\tlearn: 0.0622001\ttotal: 24.7s\tremaining: 897ms\n",
      "965:\tlearn: 0.0621173\ttotal: 24.7s\tremaining: 871ms\n",
      "966:\tlearn: 0.0620489\ttotal: 24.8s\tremaining: 845ms\n",
      "967:\tlearn: 0.0619913\ttotal: 24.8s\tremaining: 820ms\n",
      "968:\tlearn: 0.0619602\ttotal: 24.8s\tremaining: 794ms\n",
      "969:\tlearn: 0.0619012\ttotal: 24.8s\tremaining: 768ms\n",
      "970:\tlearn: 0.0618428\ttotal: 24.9s\tremaining: 743ms\n",
      "971:\tlearn: 0.0617606\ttotal: 24.9s\tremaining: 717ms\n",
      "972:\tlearn: 0.0617218\ttotal: 24.9s\tremaining: 691ms\n",
      "973:\tlearn: 0.0616966\ttotal: 24.9s\tremaining: 666ms\n",
      "974:\tlearn: 0.0616416\ttotal: 25s\tremaining: 640ms\n",
      "975:\tlearn: 0.0616147\ttotal: 25s\tremaining: 614ms\n",
      "976:\tlearn: 0.0615581\ttotal: 25s\tremaining: 589ms\n",
      "977:\tlearn: 0.0615058\ttotal: 25s\tremaining: 563ms\n",
      "978:\tlearn: 0.0614265\ttotal: 25.1s\tremaining: 538ms\n",
      "979:\tlearn: 0.0613898\ttotal: 25.1s\tremaining: 512ms\n",
      "980:\tlearn: 0.0613310\ttotal: 25.1s\tremaining: 486ms\n",
      "981:\tlearn: 0.0612768\ttotal: 25.1s\tremaining: 461ms\n",
      "982:\tlearn: 0.0612342\ttotal: 25.2s\tremaining: 435ms\n",
      "983:\tlearn: 0.0611796\ttotal: 25.2s\tremaining: 409ms\n",
      "984:\tlearn: 0.0611269\ttotal: 25.2s\tremaining: 384ms\n",
      "985:\tlearn: 0.0610748\ttotal: 25.2s\tremaining: 358ms\n",
      "986:\tlearn: 0.0610089\ttotal: 25.3s\tremaining: 333ms\n",
      "987:\tlearn: 0.0609760\ttotal: 25.3s\tremaining: 307ms\n",
      "988:\tlearn: 0.0609570\ttotal: 25.3s\tremaining: 281ms\n",
      "989:\tlearn: 0.0608999\ttotal: 25.3s\tremaining: 256ms\n",
      "990:\tlearn: 0.0608289\ttotal: 25.3s\tremaining: 230ms\n",
      "991:\tlearn: 0.0608029\ttotal: 25.4s\tremaining: 205ms\n",
      "992:\tlearn: 0.0607505\ttotal: 25.4s\tremaining: 179ms\n",
      "993:\tlearn: 0.0606929\ttotal: 25.4s\tremaining: 153ms\n",
      "994:\tlearn: 0.0606448\ttotal: 25.4s\tremaining: 128ms\n",
      "995:\tlearn: 0.0605881\ttotal: 25.5s\tremaining: 102ms\n",
      "996:\tlearn: 0.0605353\ttotal: 25.5s\tremaining: 76.7ms\n",
      "997:\tlearn: 0.0604959\ttotal: 25.5s\tremaining: 51.1ms\n",
      "998:\tlearn: 0.0604595\ttotal: 25.5s\tremaining: 25.6ms\n",
      "999:\tlearn: 0.0604439\ttotal: 25.6s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        41\n",
      "           1       0.78      0.60      0.68        30\n",
      "           2       0.58      0.60      0.59        25\n",
      "           3       0.48      0.50      0.49        28\n",
      "           4       0.62      0.63      0.63        49\n",
      "           5       0.60      0.67      0.63        39\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.61      0.60      0.60       212\n",
      "weighted avg       0.61      0.61      0.61       212\n"
     ]
    }
   ],
   "source": [
    "#perform catboost to classify the words\n",
    "cat = CatBoostClassifier(task_type='GPU')\n",
    "\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "predictions = cat.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get an accuracy of 0.61, which is not higher than the other models, even without optimization."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "646e5fc094006073"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we move on with neural networks\n",
    "\n",
    "We start by one-hot encoding both y training and y test labels to accommodate the 6-class output, and then proceed to build a sequential neural network model. The sequential architecture starts with a dense layer of 32 units with 'relu' activation, adapted for 768 input features, and incorporates L1 and L2 regularization to mitigate overfitting. Following this, batch normalization is applied to stabilize learning, succeeded by a substantial dropout rate of 0.6 to further prevent overfitting. Another 'relu' activated dense layer with 12 units also includes regularization, succeeded by batch normalization, leading in a softmax-activated dense layer for class prediction. The model employs the Adam optimizer and categorical crossentropy loss function, with accuracy as the performance metric.\n",
    " \n",
    "An EarlyStopping callback is integrated to cease training if no improvement in validation loss is observed for 10 epochs. The training process, is set for a maximum of 40 epochs with a batch size of 32 and utilizing 20% of the data for validation. Finaly the model's performance is evaluated on the test set, through the loss and accuracy metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c092cbdbacf423ba"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2038bde37e6349a2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:48:12.138611900Z",
     "start_time": "2024-02-24T13:48:06.894374800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "22/22 [==============================] - 3s 14ms/step - loss: 3.3141 - accuracy: 0.1760 - val_loss: 2.9438 - val_accuracy: 0.1775\n",
      "Epoch 2/40\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2.9921 - accuracy: 0.2633 - val_loss: 2.8885 - val_accuracy: 0.1598\n",
      "Epoch 3/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.7888 - accuracy: 0.3402 - val_loss: 2.8384 - val_accuracy: 0.1598\n",
      "Epoch 4/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.6163 - accuracy: 0.3757 - val_loss: 2.7894 - val_accuracy: 0.1598\n",
      "Epoch 5/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.5065 - accuracy: 0.3994 - val_loss: 2.7428 - val_accuracy: 0.1598\n",
      "Epoch 6/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.4619 - accuracy: 0.4231 - val_loss: 2.6920 - val_accuracy: 0.1834\n",
      "Epoch 7/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.3437 - accuracy: 0.4630 - val_loss: 2.6397 - val_accuracy: 0.2426\n",
      "Epoch 8/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.2801 - accuracy: 0.4527 - val_loss: 2.5911 - val_accuracy: 0.2544\n",
      "Epoch 9/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.2247 - accuracy: 0.4734 - val_loss: 2.5388 - val_accuracy: 0.2544\n",
      "Epoch 10/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.1535 - accuracy: 0.4985 - val_loss: 2.4856 - val_accuracy: 0.2722\n",
      "Epoch 11/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.0756 - accuracy: 0.5399 - val_loss: 2.4347 - val_accuracy: 0.2959\n",
      "Epoch 12/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.0493 - accuracy: 0.5266 - val_loss: 2.3922 - val_accuracy: 0.3195\n",
      "Epoch 13/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9950 - accuracy: 0.5533 - val_loss: 2.3407 - val_accuracy: 0.3491\n",
      "Epoch 14/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9376 - accuracy: 0.5651 - val_loss: 2.3131 - val_accuracy: 0.3018\n",
      "Epoch 15/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9120 - accuracy: 0.5636 - val_loss: 2.2538 - val_accuracy: 0.3728\n",
      "Epoch 16/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8571 - accuracy: 0.5902 - val_loss: 2.2122 - val_accuracy: 0.4201\n",
      "Epoch 17/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8088 - accuracy: 0.5828 - val_loss: 2.1861 - val_accuracy: 0.4260\n",
      "Epoch 18/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8021 - accuracy: 0.5740 - val_loss: 2.1730 - val_accuracy: 0.3787\n",
      "Epoch 19/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7548 - accuracy: 0.5976 - val_loss: 2.1747 - val_accuracy: 0.3728\n",
      "Epoch 20/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7204 - accuracy: 0.6036 - val_loss: 2.0595 - val_accuracy: 0.4675\n",
      "Epoch 21/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6711 - accuracy: 0.6169 - val_loss: 1.9714 - val_accuracy: 0.5030\n",
      "Epoch 22/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6635 - accuracy: 0.6109 - val_loss: 1.8800 - val_accuracy: 0.5858\n",
      "Epoch 23/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6269 - accuracy: 0.6361 - val_loss: 1.8357 - val_accuracy: 0.5799\n",
      "Epoch 24/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6150 - accuracy: 0.6272 - val_loss: 1.8616 - val_accuracy: 0.5444\n",
      "Epoch 25/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5498 - accuracy: 0.6317 - val_loss: 1.8046 - val_accuracy: 0.5444\n",
      "Epoch 26/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5151 - accuracy: 0.6479 - val_loss: 1.6697 - val_accuracy: 0.6568\n",
      "Epoch 27/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4948 - accuracy: 0.6701 - val_loss: 1.6747 - val_accuracy: 0.6509\n",
      "Epoch 28/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5142 - accuracy: 0.6376 - val_loss: 1.6965 - val_accuracy: 0.6154\n",
      "Epoch 29/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5025 - accuracy: 0.6524 - val_loss: 1.6891 - val_accuracy: 0.5917\n",
      "Epoch 30/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4572 - accuracy: 0.6701 - val_loss: 1.6114 - val_accuracy: 0.6154\n",
      "Epoch 31/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4634 - accuracy: 0.6524 - val_loss: 1.5524 - val_accuracy: 0.6627\n",
      "Epoch 32/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4027 - accuracy: 0.6775 - val_loss: 1.5707 - val_accuracy: 0.6509\n",
      "Epoch 33/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3502 - accuracy: 0.6982 - val_loss: 1.5810 - val_accuracy: 0.6450\n",
      "Epoch 34/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3364 - accuracy: 0.6820 - val_loss: 1.5486 - val_accuracy: 0.6627\n",
      "Epoch 35/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2978 - accuracy: 0.6997 - val_loss: 1.5329 - val_accuracy: 0.6746\n",
      "Epoch 36/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.7322 - val_loss: 1.5196 - val_accuracy: 0.6154\n",
      "Epoch 37/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3592 - accuracy: 0.6923 - val_loss: 1.5305 - val_accuracy: 0.6509\n",
      "Epoch 38/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.6938 - val_loss: 1.5751 - val_accuracy: 0.6095\n",
      "Epoch 39/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2990 - accuracy: 0.6997 - val_loss: 1.5307 - val_accuracy: 0.6272\n",
      "Epoch 40/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3113 - accuracy: 0.7115 - val_loss: 1.5129 - val_accuracy: 0.6568\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5468 - accuracy: 0.6509\n",
      "Loss: 1.5468294620513916, Accuracy: 0.650943398475647\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels if they are categorical\n",
    "y_train_encoded = to_categorical(y_train, num_classes=6)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=6)\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(768,), kernel_regularizer=l1_l2(l1=0.001, l2=0.001)), \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.6),  # Increased dropout rate\n",
    "    Dense(12, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dense(6, activation='softmax') \n",
    "])\n",
    "\n",
    "# Compile the model with a smaller learning rate\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# EarlyStopping callback to stop training when no improvement in val_loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with encoded labels and callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train_encoded, \n",
    "    epochs=40,  # Increase if needed\n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model with encoded labels\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy is 0.65 which is around the same as the other models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c15138a8f9dfd47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking the best epoch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7bc390a4168d9cc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print best epoch\n",
    "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "best_epoch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:48:14.949510300Z",
     "start_time": "2024-02-24T13:48:14.933584600Z"
    }
   },
   "id": "edfb5491594866ba",
   "execution_count": 150
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we create two subplots to visualize the training and validation accuracy and loss over the epochs, and to check for overfitting."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a86cbc69942bd799"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1400x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve the history data from the history object\n",
    "history_data = history.history\n",
    "\n",
    "# List of epochs\n",
    "epochs = range(1, len(history_data['accuracy']) + 1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history_data['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs, history_data['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history_data['loss'], label='Training Loss')\n",
    "plt.plot(epochs, history_data['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:48:16.349294200Z",
     "start_time": "2024-02-24T13:48:16.042951200Z"
    }
   },
   "id": "906dae26c6174b95",
   "execution_count": 151
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Discussion I***\n",
    "\n",
    "The training and validation accuracy and loss plots, with the best epoch being 40, do not strongly suggest overfitting, as the validation accuracy does not significantly diverge from the training accuracy, and the validation loss does not show a rising trend. While the training accuracy continues to improve slightly, the validation accuracy plateaus with some fluctuation, but without a distinct downward trend. Similarly, the training loss decreases steadily, and the validation loss levels off without increasing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b509087acea40448"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Discussion II***\n",
    "\n",
    "Based on the classification results, the support vector machine (SVM) model with optimized hyperparameters achieved the highest accuracy of 0.71. An accuracy of 0.71 means that the SVM model correctly predicted the class labels for 71% of the instances in the test dataset or in other words, for each 100 words the model correctly predicted the correct CLASSES of the words 71 times."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33aab8db61a66387"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification on the second hierarchical level (SECTION/DIVISION)\n",
    "\n",
    "To tackle this problem, we will take the model with the best accuracy, which is the SVM model, and adapt it for multi-label classification. We will use the MultiOutputClassifier from scikit-learn to adapt the SVM model for multi-label classification. The MultiOutputClassifier is a simple strategy for extending classifiers that do not natively support multi-target classification. It works by fitting one classifier per target."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e5d351b22ca9bc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by creating a new Y_train and Y_test with both the class and the sec_div"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b387a4ce0bae66b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Make a new Y_train and Y_test with both the class and the sec_div\n",
    "Y = classification[['class', 'sec_div']]-1\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:25:40.926085200Z",
     "start_time": "2024-02-24T13:25:40.901977100Z"
    }
   },
   "id": "4ce9c1a024fccec8",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then initialize the multioutput classifier and fit the model with the optimal hyperparameters of the previous SVM model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bafd46720115d68"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "base_classifier = SVC(C=best_params_svm['C'], kernel=best_params_svm['kernel'], degree=best_params_svm['degree'], gamma=best_params_svm['gamma'])\n",
    "\n",
    "# Adapt SVM for multi-label classification\n",
    "multi_label_svm = MultiOutputClassifier(base_classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:35.660964200Z",
     "start_time": "2024-02-24T14:49:35.635658700Z"
    }
   },
   "id": "e4b1edde43d9b6a7",
   "execution_count": 154
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we fit and predict the model while also evaluating the accuracy for each target."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2843811ab3aef047"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 accuracy: 0.7122641509433962\n",
      "Target 1 accuracy: 0.5330188679245284\n"
     ]
    }
   ],
   "source": [
    "#initialize the multioutput classifier\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "#fit the model\n",
    "multi_target_classifier.fit(X_train, Y_train)\n",
    "\n",
    "#predict the model\n",
    "predictions = multi_target_classifier.predict(X_test)\n",
    "\n",
    "# Example evaluation for each target\n",
    "for i in range(Y_test.shape[1]):\n",
    "    # Use .iloc to select all rows and the ith column for both Y_test and predictions\n",
    "    accuracy = accuracy_score(Y_test.iloc[:, i], predictions[:, i])\n",
    "    print(f\"Target {i} accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:36.946787600Z",
     "start_time": "2024-02-24T14:49:36.248632200Z"
    }
   },
   "id": "4521d54cb57f273a",
   "execution_count": 155
  },
  {
   "cell_type": "markdown",
   "source": [
    "Target 0 accuracy: The accuracy of 0.71 for Target 0 means that for the first classification task, the model correctly predicted the class labels 71.23% of the time. Which is some thing that we have already seen in the previous classification.\n",
    "\n",
    "Target 1 accuracy: The accuracy of 0.53 for Target 1 means that for the second classification task, the model correctly predicted the section/division labels 53.30% of the time. This is lower than the first classification task, which is expected as the second classification task is more complex than the first one.\n",
    "\n",
    "finally we can calculate the multi-output accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a5546dea4a3da2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below code compares all predicted labels to the true labels for each sample and computes the average of completely correct predictions across the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acb528ae756e8196"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-output Accuracy: 0.44339622641509435\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(np.all(Y_test == predictions, axis=1))\n",
    "print(f\"Multi-output Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:53:07.929853700Z",
     "start_time": "2024-02-24T15:53:07.903072800Z"
    }
   },
   "id": "7f2fa5907ad03e5c",
   "execution_count": 157
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above accuracy of 0.44, we can see that the model correctly predicted the class and section/division labels for 44% of the instances in the test dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e0d6b904f2be245"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
